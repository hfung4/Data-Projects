{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%run helpers.ipynb\n",
    "\n",
    "'''Visualization'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "''' Features'''\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "'''Estimators'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "'''Modelling'''\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score \n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the SecReq datasets\n",
    "CPN = pd.read_csv(\"../data/CPN.csv\", sep=\";\", names=[\"text\", \"labels\"])\n",
    "GPS = pd.read_csv(\"../data/GPS.csv\", sep=\";\", names=[\"text\", \"labels\"])\n",
    "ePurse = pd.read_csv(\"../data/ePurse_selective.csv\", sep=\";\", names=[\"text\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the nfr dataset\n",
    "nfr = pd.read_csv(\"../data/nfr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data in the labels column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 2), (178, 2), (124, 2), (625, 3))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPN.shape, GPS.shape, ePurse.shape, nfr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Internally to the CPN, a CNG transmitting pri...</td>\n",
       "      <td>sec,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internally to the CPN, a CNG receiving privat...</td>\n",
       "      <td>sec,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The CNG shall detect the end of the life of th...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A CPN-user attempting to invoke a CNG-mediate...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The CNG shall implement an authentication fail...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     labels\n",
       "0   Internally to the CPN, a CNG transmitting pri...   sec,,,,,\n",
       "1   Internally to the CPN, a CNG receiving privat...   sec,,,,,\n",
       "2  The CNG shall detect the end of the life of th...  sec,,,,,,\n",
       "3   A CPN-user attempting to invoke a CNG-mediate...  sec,,,,,,\n",
       "4  The CNG shall implement an authentication fail...  sec,,,,,,"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The system shall refresh the display every 60 ...</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The application shall match the color of the s...</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected  the data must be readable.  On ...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The product shall be available during normal ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected  the data must be understandable...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProjectID                                               text labels\n",
       "0          1  The system shall refresh the display every 60 ...     PE\n",
       "1          1  The application shall match the color of the s...     LF\n",
       "2          1   If projected  the data must be readable.  On ...     US\n",
       "3          1   The product shall be available during normal ...      A\n",
       "4          1   If projected  the data must be understandable...     US"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(\"CPN\",CPN), (\"GPS\",GPS), (\"ePurse\",ePurse), (\"nfr\",nfr)] # a list of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some basic cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean some of the wierd \",,,,,\" in labels\n",
    "def clean_labels(df):\n",
    "    df[\"labels\"] = df[\"labels\"].map(lambda x: re.sub(\",|\\\"\",\"\",str(x)))\n",
    "    df['labels'] = df['labels'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in datasets[:-1]:\n",
    "    clean_labels(df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check to see if there is class imbalances for each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_counts(df):\n",
    "    # count of each level\n",
    "    count = df[\"labels\"].value_counts(dropna=False)\n",
    "    # percentage of each level\n",
    "    percent = round(df[\"labels\"].value_counts(dropna=False, normalize=True)*100, 3)\n",
    "    \n",
    "    # put it into a DataFrame\n",
    "    return pd.concat([count,percent], axis=1, keys=[\"count\", \"percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPN:\n",
      "        count  percentage\n",
      "nonsec    167      79.524\n",
      "sec        41      19.524\n",
      "nan         2       0.952\n",
      "\n",
      "\n",
      "GPS:\n",
      "        count  percentage\n",
      "nonsec     94      52.809\n",
      "sec        45      25.281\n",
      "nan        37      20.787\n",
      "xyz         1       0.562\n",
      "            1       0.562\n",
      "\n",
      "\n",
      "ePurse:\n",
      "        count  percentage\n",
      "sec        83      66.935\n",
      "nonsec     41      33.065\n",
      "\n",
      "\n",
      "nfr:\n",
      "    count  percentage\n",
      "F     255       40.80\n",
      "US     67       10.72\n",
      "SE     66       10.56\n",
      "O      62        9.92\n",
      "PE     54        8.64\n",
      "LF     38        6.08\n",
      "A      21        3.36\n",
      "SC     21        3.36\n",
      "MN     17        2.72\n",
      "L      13        2.08\n",
      "FT     10        1.60\n",
      "PO      1        0.16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in datasets:\n",
    "    print(f\"{df[0]}:\")\n",
    "    pprint.pprint(level_counts(df[1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's drop the rows with label as nan in CPN and blank and xyz in GPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPN = CPN.loc[(CPN[\"labels\"] == \"sec\") | (CPN[\"labels\"] == \"nonsec\") , :]  # highly imbalanced: 80% nonsec, 20% sec\n",
    "GPS = GPS.loc[(GPS[\"labels\"] == \"sec\") | (GPS[\"labels\"] == \"nonsec\") , :]  # imbalanced: 67% nonsec, 32% sec\n",
    "ePurse = ePurse.loc[(ePurse[\"labels\"] == \"sec\") | (ePurse[\"labels\"] == \"nonsec\") , :] # imbalanced: 66% nonsec, 33% sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the nfr dataset, there are some labels with very little samples.  I can try to group all classes with less than 7% to a single \"other\" class\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = level_counts(nfr)\n",
    "others=list(temp[temp.percentage<7].index) # a list of classes that I want to group as \"others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfr.loc[nfr.labels.isin(others), \"labels\"]= \"others\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>255</td>\n",
       "      <td>40.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>121</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>67</td>\n",
       "      <td>10.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>66</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>62</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>54</td>\n",
       "      <td>8.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  percentage\n",
       "F         255       40.80\n",
       "others    121       19.36\n",
       "US         67       10.72\n",
       "SE         66       10.56\n",
       "O          62        9.92\n",
       "PE         54        8.64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_counts(nfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine CPN, GPS, ePurse datasets into a single SeqReq dataset.  We will perform binary classification on this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecReq = pd.concat([CPN,GPS,ePurse], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecReq = SecReq.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A credit command, which contains the S2 MAC co...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPN environment shall be protected with a stat...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the CNG management it is recommended to us...</td>\n",
       "      <td>nonsec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All other commands (including SELECT commands...</td>\n",
       "      <td>nonsec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codec requirements and capabilities for the Us...</td>\n",
       "      <td>nonsec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  A credit command, which contains the S2 MAC co...     sec\n",
       "1  CPN environment shall be protected with a stat...     sec\n",
       "2  For the CNG management it is recommended to us...  nonsec\n",
       "3   All other commands (including SELECT commands...  nonsec\n",
       "4  Codec requirements and capabilities for the Us...  nonsec"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SecReq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process software requirements text\n",
    "- Use spaCy to remove puncutation, non-alphanumric data, and elmmatize the text.\n",
    "- Train and apply first-order phrase model to join word pairs (get bigrams).\n",
    "- Train and apply second-order phrase model to join word triplets (get trigrams).\n",
    "- Remove stopwords.\n",
    "- Create tf-idf representations.\n",
    "\n",
    "Useful reference: https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process text\n",
    "process_text(SecReq)\n",
    "process_text(nfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modelling\n",
    "- Learn combinations of tokens that together represents meaningful multi-word phrases (\"United States\", \"happy hour\")\n",
    "- Use gensim to develop phrase models phrase models are developed by examining all the words in The headlines and looking for words that co-occur (i.e., appear one after another) together much more frequently than you would expect them to by random chance.\n",
    "- Once our phrase model has been trained on our corpus, we can apply it to new text. When our model encounters two tokens in new text that identifies as a phrase, it will merge the two into a single new token.\n",
    "\n",
    "Useful reference: https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-7-phrase-modeling-doc2vec-592a8a996867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phraser model, get bigrams\n",
    "model_filepath = \"../models/secreq_bigrams_model\" # bigram model file path for SecReq\n",
    "get_bigrams(SecReq, model_filepath, True)\n",
    "\n",
    "model_filepath = \"../models/nfr_bigrams_model\" # bigram model file path for nfr\n",
    "get_bigrams(nfr, model_filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phraser model, get trigrams\n",
    "model_filepath = \"../models/secreq_trigrams_model\" # bigram model file path for SecReq\n",
    "get_trigrams(SecReq, model_filepath, True)\n",
    "\n",
    "model_filepath = \"../models/nfr_trigrams_model\" # bigram model file path for nfr\n",
    "get_trigrams(nfr, model_filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>The CNG shall support mechanisms for secure au...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[cng, shall, support, mechanism, secure, authe...</td>\n",
       "      <td>[cng, shall, support_mechanism, secure, authen...</td>\n",
       "      <td>[cng, shall_support_mechanism, secure, authent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>The GlobalPlatform Environment (OPEN) support...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[globalplatform, environment, open, support, c...</td>\n",
       "      <td>[globalplatform, environment, open, support, c...</td>\n",
       "      <td>[globalplatform, environment, open, support, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The management of keys must be accomplished in...</td>\n",
       "      <td>sec</td>\n",
       "      <td>[management, key, accomplish, secure, certifie...</td>\n",
       "      <td>[management, key, accomplish, secure, certifie...</td>\n",
       "      <td>[management, key, accomplish, secure, certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>A GlobalPlatform card should support symmetri...</td>\n",
       "      <td>sec</td>\n",
       "      <td>[globalplatform, card, support, symmetric, cry...</td>\n",
       "      <td>[globalplatform, card, support, symmetric, cry...</td>\n",
       "      <td>[globalplatform, card, support, symmetric, cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>The CND should support protocols for remote ac...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[cnd, support, protocol, remote, access, manag...</td>\n",
       "      <td>[cnd, support, protocol, remote_access, manage...</td>\n",
       "      <td>[cnd, support, protocol, remote_access, manage...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  \\\n",
       "384  The CNG shall support mechanisms for secure au...  nonsec   \n",
       "328   The GlobalPlatform Environment (OPEN) support...  nonsec   \n",
       "91   The management of keys must be accomplished in...     sec   \n",
       "430   A GlobalPlatform card should support symmetri...     sec   \n",
       "431  The CND should support protocols for remote ac...  nonsec   \n",
       "\n",
       "                                        processed_text  \\\n",
       "384  [cng, shall, support, mechanism, secure, authe...   \n",
       "328  [globalplatform, environment, open, support, c...   \n",
       "91   [management, key, accomplish, secure, certifie...   \n",
       "430  [globalplatform, card, support, symmetric, cry...   \n",
       "431  [cnd, support, protocol, remote, access, manag...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "384  [cng, shall, support_mechanism, secure, authen...   \n",
       "328  [globalplatform, environment, open, support, c...   \n",
       "91   [management, key, accomplish, secure, certifie...   \n",
       "430  [globalplatform, card, support, symmetric, cry...   \n",
       "431  [cnd, support, protocol, remote_access, manage...   \n",
       "\n",
       "                                              trigrams  \n",
       "384  [cng, shall_support_mechanism, secure, authent...  \n",
       "328  [globalplatform, environment, open, support, c...  \n",
       "91   [management, key, accomplish, secure, certifie...  \n",
       "430  [globalplatform, card, support, symmetric, cry...  \n",
       "431  [cnd, support, protocol, remote_access, manage...  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SecReq.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>The product shall be installed by an untrained...</td>\n",
       "      <td>US</td>\n",
       "      <td>[product, shall, instal, untrained, realtor, r...</td>\n",
       "      <td>[product, shall, instal, untrained, realtor, r...</td>\n",
       "      <td>[product, shall, instal, untrained, realtor, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>8</td>\n",
       "      <td>System shall let Izogn Manager access sales an...</td>\n",
       "      <td>PE</td>\n",
       "      <td>[system, shall, let, izogn, manager, access, s...</td>\n",
       "      <td>[system, shall, let, izogn, manager, access, s...</td>\n",
       "      <td>[system, shall, let, izogn, manager, access, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>8</td>\n",
       "      <td>All streaming movie sales will be logged in t...</td>\n",
       "      <td>F</td>\n",
       "      <td>[stream, movie, sale, log, database, accessibl...</td>\n",
       "      <td>[stream_movie, sale, log, database, accessible...</td>\n",
       "      <td>[stream_movie, sale, log, database, accessible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>The system shall contain contact information ...</td>\n",
       "      <td>F</td>\n",
       "      <td>[system, shall, contain, contact, information,...</td>\n",
       "      <td>[system, shall, contain, contact_information, ...</td>\n",
       "      <td>[system, shall, contain, contact_information, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>13</td>\n",
       "      <td>The system shall only be accessed by authorize...</td>\n",
       "      <td>SE</td>\n",
       "      <td>[system, shall, access, authorize, corporate, ...</td>\n",
       "      <td>[system, shall, access, authorize, corporate, ...</td>\n",
       "      <td>[system, shall, access, authorize, corporate, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectID                                               text labels  \\\n",
       "51           2  The product shall be installed by an untrained...     US   \n",
       "382          8  System shall let Izogn Manager access sales an...     PE   \n",
       "462          8   All streaming movie sales will be logged in t...      F   \n",
       "136          3   The system shall contain contact information ...      F   \n",
       "595         13  The system shall only be accessed by authorize...     SE   \n",
       "\n",
       "                                        processed_text  \\\n",
       "51   [product, shall, instal, untrained, realtor, r...   \n",
       "382  [system, shall, let, izogn, manager, access, s...   \n",
       "462  [stream, movie, sale, log, database, accessibl...   \n",
       "136  [system, shall, contain, contact, information,...   \n",
       "595  [system, shall, access, authorize, corporate, ...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "51   [product, shall, instal, untrained, realtor, r...   \n",
       "382  [system, shall, let, izogn, manager, access, s...   \n",
       "462  [stream_movie, sale, log, database, accessible...   \n",
       "136  [system, shall, contain, contact_information, ...   \n",
       "595  [system, shall, access, authorize, corporate, ...   \n",
       "\n",
       "                                              trigrams  \n",
       "51   [product, shall, instal, untrained, realtor, r...  \n",
       "382  [system, shall, let, izogn, manager, access, s...  \n",
       "462  [stream_movie, sale, log, database, accessible...  \n",
       "136  [system, shall, contain, contact_information, ...  \n",
       "595  [system, shall, access, authorize, corporate, ...  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfr.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variant of the nfr dataset in which there are only two classes: functional (F) and non-functional (NF)\n",
    "nfr_binary = nfr.copy()\n",
    "nfr_binary[\"labels\"].replace([\"others\",\"US\",\"SE\",\"O\",\"PE\"], \"NF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels to numeric value\n",
    "encode_label(SecReq)\n",
    "encode_label(nfr)\n",
    "encode_label(nfr_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "secreq_texts = SecReq['trigrams'].astype('str')\n",
    "nfr_texts = nfr_binary_texts = nfr['trigrams'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for the SecReq dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline for modelling**\n",
    "- Convert the transformed text (with trigrams) to a matrix of tf-idf weights (features)\n",
    "- The matrix would contain the tf-idf scores of each token t in each of the document in the corpus.\n",
    "- Perform TruncatedSVD to reduce the number of features-- this is important since our sample size is small, a large feature set will lead to overfitting.\n",
    "- Modelling: use RandomForest and Adaboost\n",
    "- Tune hyperparameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test harness\n",
    "X = secreq_texts\n",
    "y = SecReq['labels_num'].values \n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "models = {\n",
    "    'SVC': SVC(random_state=10),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=10),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameters for GridSearchCV\n",
    "# Use a dictionary of dictionaries to set the param grid for each of the models\n",
    "'''\n",
    "SVC:\n",
    "C = the regularization parameter, penalize model complexity\n",
    "gamma = kernel coefficient for ‘rbf’ \n",
    "\n",
    "\n",
    "Random Forest:\n",
    "n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "\n",
    "AdaBoost:\n",
    "n_estimators = number of estimators in the boosted ensemble to use.\n",
    "learning_rate= Learning rate shrinks the contribution of each classifier by learning_rate. \n",
    "'''       \n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "params = {\n",
    "    \n",
    "    'SVC':  { \n",
    "        \"clf__C\" : [ 1, 10, 100, 1000], # [1,10,100,1000]\n",
    "        \"clf__gamma\" : [1,0.1,0.001,0.0001], # [1,0.1,0.001,0.0001]\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier':  { \n",
    "        \"clf__n_estimators\" : [200, 400, 800, 1000, 1200], # [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800] \n",
    "        \"clf__max_depth\"      : [10,30,50,80,100],  # [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "        \"clf__min_samples_split\" : [3,5,6],  # [2, 5, 10]\n",
    "        \"clf__min_samples_leaf\" :   [2,3]   # [1, 2, 4]  \n",
    "    },\n",
    "    \n",
    "    'AdaBoostClassifier':  { \n",
    "        \"clf__n_estimators\" : [100, 500, 800, 1000], # [100, 500, 800, 1000]\n",
    "        \"clf__learning_rate\" : [0.01,0.05,0.1,0.3,1] # [0.01,0.05,0.1,0.3,1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secreq_tfidf = models_training(\"SecReq\",\"tfidf\", X_train, y_train, X_test, y_test, models, params, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>wv_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.954105</td>\n",
       "      <td>0.954105</td>\n",
       "      <td>0.954105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.958086</td>\n",
       "      <td>0.949795</td>\n",
       "      <td>0.953696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.947820</td>\n",
       "      <td>0.916074</td>\n",
       "      <td>0.928822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset wv_type              model_name  accuracy_score  precision_score  \\\n",
       "0  SecReq   tfidf                     SVC        0.957746         0.954105   \n",
       "2  SecReq   tfidf      AdaBoostClassifier        0.957746         0.958086   \n",
       "1  SecReq   tfidf  RandomForestClassifier        0.936620         0.947820   \n",
       "\n",
       "   recall_score  f1_score  \n",
       "0      0.954105  0.954105  \n",
       "2      0.949795  0.953696  \n",
       "1      0.916074  0.928822  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_secreq_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thoughts:**\n",
    "- I should select SVC since it requires the least training time and it has the best performance (on the test data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for the nfr_binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test harness\n",
    "X = nfr_binary_texts\n",
    "y = nfr_binary['labels_num'].values \n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfr_binary_tfidf = models_training(\"nfr_binary\",\"tfidf\", X_train, y_train, X_test, y_test, models, params, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>wv_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.875415</td>\n",
       "      <td>0.870539</td>\n",
       "      <td>0.872730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.845745</td>\n",
       "      <td>0.864589</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.832427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.811198</td>\n",
       "      <td>0.779630</td>\n",
       "      <td>0.787558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset wv_type              model_name  accuracy_score  \\\n",
       "0  nfr_binary   tfidf                     SVC        0.877660   \n",
       "1  nfr_binary   tfidf  RandomForestClassifier        0.845745   \n",
       "2  nfr_binary   tfidf      AdaBoostClassifier        0.803191   \n",
       "\n",
       "   precision_score  recall_score  f1_score  \n",
       "0         0.875415      0.870539  0.872730  \n",
       "1         0.864589      0.821633  0.832427  \n",
       "2         0.811198      0.779630  0.787558  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfr_binary_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to represent software requirements with pre-trained Sentence Embeddings \n",
    "Useful Reference: https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Load KeyedVectors for the Google News word embeddings\n",
    "# Contains 3 million 300-D word embeddings trained from 100 billion words\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "# The vectors is loaded from an existing file on disk in the original Google’s word2vec C format as \n",
    "#a KeyedVectors instance\n",
    "googlew2v = KeyedVectors.load_word2vec_format('../embeddings/GoogleNews-vectors-negative300.bin.gz', \n",
    "                                                            binary=True) # C bin format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure. The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}. Note that with KeyVectors, I cannot continue to train the vectors.  However, KeyedVectors are smaller and need less RAM since htey don't need to store the model state that enbales training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transformed requirements from each dataset a list of lists of tokens\n",
    "nfr_docs = nfr.trigrams.tolist()\n",
    "secreq_docs = SecReq.trigrams.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(doc):\n",
    "    # only keep tokens in each sentence if they are a vocab in googlew2v\n",
    "    tokens_in_embedding= [t for t in doc if t in googlew2v] \n",
    "    sent_embedding = np.average([googlew2v[token] for token in tokens_in_embedding], axis=0)\n",
    "    return sent_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentence embeddings of each of the 625 requirements in the nfr dataset\n",
    "# For each requirements, I get the 300x1 word embedding for each token, and then take the average \n",
    "# to get a 300x1 sentence embedding\n",
    "sent_embeddings_nfr= [get_sentence_embeddings(doc) for doc in nfr_docs] # a list of 625 ndarrays of 300 elements\n",
    "sent_embeddings_nfr = np.concatenate(sent_embeddings_nfr, axis=0) # an ndarray of 625x300=187500 elements\n",
    "sent_embeddings_nfr = sent_embeddings_nfr.reshape((625,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_embeddings_secreq = [get_sentence_embeddings(doc) for doc in secreq_docs] # a list of 471 ndarrays of 300 elements\n",
    "sent_embeddings_secreq = np.concatenate(sent_embeddings_secreq, axis=0) # an ndarray of 471x300=141300 elements\n",
    "sent_embeddings_secreq = sent_embeddings_secreq.reshape((471,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test harness\n",
    "X = sent_embeddings_secreq\n",
    "y = SecReq['labels_num'].values \n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secreq_wv = models_training(\"SecReq\",\"pre_trained_wv\", X_train, y_train, X_test, y_test, models, params, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>wv_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>pre_trained_wv</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.965094</td>\n",
       "      <td>0.969130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>pre_trained_wv</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.968307</td>\n",
       "      <td>0.955290</td>\n",
       "      <td>0.961234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>pre_trained_wv</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.958086</td>\n",
       "      <td>0.949795</td>\n",
       "      <td>0.953696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset         wv_type              model_name  accuracy_score  \\\n",
       "0  SecReq  pre_trained_wv                     SVC        0.971831   \n",
       "1  SecReq  pre_trained_wv  RandomForestClassifier        0.964789   \n",
       "2  SecReq  pre_trained_wv      AdaBoostClassifier        0.957746   \n",
       "\n",
       "   precision_score  recall_score  f1_score  \n",
       "0         0.973667      0.965094  0.969130  \n",
       "1         0.968307      0.955290  0.961234  \n",
       "2         0.958086      0.949795  0.953696  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_secreq_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
