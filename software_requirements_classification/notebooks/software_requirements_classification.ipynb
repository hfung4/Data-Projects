{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%run helpers.ipynb\n",
    "\n",
    "'''Visualization'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "''' Features'''\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "'''Estimators'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "'''Modelling'''\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score \n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the SecReq datasets\n",
    "CPN = pd.read_csv(\"../data/CPN.csv\", sep=\";\", names=[\"text\", \"labels\"])\n",
    "GPS = pd.read_csv(\"../data/GPS.csv\", sep=\";\", names=[\"text\", \"labels\"])\n",
    "ePurse = pd.read_csv(\"../data/ePurse_selective.csv\", sep=\";\", names=[\"text\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the nfr dataset\n",
    "nfr = pd.read_csv(\"../data/nfr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data in the labels column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 2), (178, 2), (124, 2), (625, 3))"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPN.shape, GPS.shape, ePurse.shape, nfr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Internally to the CPN, a CNG transmitting pri...</td>\n",
       "      <td>sec,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internally to the CPN, a CNG receiving privat...</td>\n",
       "      <td>sec,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The CNG shall detect the end of the life of th...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A CPN-user attempting to invoke a CNG-mediate...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The CNG shall implement an authentication fail...</td>\n",
       "      <td>sec,,,,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     labels\n",
       "0   Internally to the CPN, a CNG transmitting pri...   sec,,,,,\n",
       "1   Internally to the CPN, a CNG receiving privat...   sec,,,,,\n",
       "2  The CNG shall detect the end of the life of th...  sec,,,,,,\n",
       "3   A CPN-user attempting to invoke a CNG-mediate...  sec,,,,,,\n",
       "4  The CNG shall implement an authentication fail...  sec,,,,,,"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The system shall refresh the display every 60 ...</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The application shall match the color of the s...</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected  the data must be readable.  On ...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The product shall be available during normal ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected  the data must be understandable...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProjectID                                               text labels\n",
       "0          1  The system shall refresh the display every 60 ...     PE\n",
       "1          1  The application shall match the color of the s...     LF\n",
       "2          1   If projected  the data must be readable.  On ...     US\n",
       "3          1   The product shall be available during normal ...      A\n",
       "4          1   If projected  the data must be understandable...     US"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(\"CPN\",CPN), (\"GPS\",GPS), (\"ePurse\",ePurse), (\"nfr\",nfr)] # a list of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some basic cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean some of the wierd \",,,,,\" in labels\n",
    "def clean_labels(df):\n",
    "    df[\"labels\"] = df[\"labels\"].map(lambda x: re.sub(\",|\\\"\",\"\",str(x)))\n",
    "    df['labels'] = df['labels'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in datasets[:-1]:\n",
    "    clean_labels(df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check to see if there is class imbalances for each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_counts(df):\n",
    "    # count of each level\n",
    "    count = df[\"labels\"].value_counts(dropna=False)\n",
    "    # percentage of each level\n",
    "    percent = round(df[\"labels\"].value_counts(dropna=False, normalize=True)*100, 3)\n",
    "    \n",
    "    # put it into a DataFrame\n",
    "    return pd.concat([count,percent], axis=1, keys=[\"count\", \"percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPN:\n",
      "        count  percentage\n",
      "nonsec    167      79.524\n",
      "sec        41      19.524\n",
      "nan         2       0.952\n",
      "\n",
      "\n",
      "GPS:\n",
      "        count  percentage\n",
      "nonsec     94      52.809\n",
      "sec        45      25.281\n",
      "nan        37      20.787\n",
      "xyz         1       0.562\n",
      "            1       0.562\n",
      "\n",
      "\n",
      "ePurse:\n",
      "        count  percentage\n",
      "sec        83      66.935\n",
      "nonsec     41      33.065\n",
      "\n",
      "\n",
      "nfr:\n",
      "    count  percentage\n",
      "F     255       40.80\n",
      "US     67       10.72\n",
      "SE     66       10.56\n",
      "O      62        9.92\n",
      "PE     54        8.64\n",
      "LF     38        6.08\n",
      "SC     21        3.36\n",
      "A      21        3.36\n",
      "MN     17        2.72\n",
      "L      13        2.08\n",
      "FT     10        1.60\n",
      "PO      1        0.16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in datasets:\n",
    "    print(f\"{df[0]}:\")\n",
    "    pprint.pprint(level_counts(df[1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's drop the rows with label as nan in CPN and blank and xyz in GPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPN = CPN.loc[(CPN[\"labels\"] == \"sec\") | (CPN[\"labels\"] == \"nonsec\") , :]  # highly imbalanced: 80% nonsec, 20% sec\n",
    "GPS = GPS.loc[(GPS[\"labels\"] == \"sec\") | (GPS[\"labels\"] == \"nonsec\") , :]  # imbalanced: 67% nonsec, 32% sec\n",
    "ePurse = ePurse.loc[(ePurse[\"labels\"] == \"sec\") | (ePurse[\"labels\"] == \"nonsec\") , :] # imbalanced: 66% nonsec, 33% sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the nfr dataset, there are some labels with very little samples.  I can try to group all classes with less than 7% to a single \"other\" class\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = level_counts(nfr)\n",
    "others=list(temp[temp.percentage<7].index) # a list of classes that I want to group as \"others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfr.loc[nfr.labels.isin(others), \"labels\"]= \"others\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>255</td>\n",
       "      <td>40.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>121</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>67</td>\n",
       "      <td>10.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>66</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>62</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>54</td>\n",
       "      <td>8.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  percentage\n",
       "F         255       40.80\n",
       "others    121       19.36\n",
       "US         67       10.72\n",
       "SE         66       10.56\n",
       "O          62        9.92\n",
       "PE         54        8.64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_counts(nfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine CPN, GPS, ePurse datasets into a single SeqReq dataset.  We will perform binary classification on this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecReq = pd.concat([CPN,GPS,ePurse], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecReq = SecReq.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amount to be reversed is the amount of the...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since these transactions are on-line to the is...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The card verification method indicator (CVMI) ...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The CEP card verifies that the PSAM is the PSA...</td>\n",
       "      <td>sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNG shall perform a link layer multicast to un...</td>\n",
       "      <td>nonsec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  The amount to be reversed is the amount of the...     sec\n",
       "1  Since these transactions are on-line to the is...     sec\n",
       "2  The card verification method indicator (CVMI) ...     sec\n",
       "3  The CEP card verifies that the PSAM is the PSA...     sec\n",
       "4  CNG shall perform a link layer multicast to un...  nonsec"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SecReq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process software requirements text\n",
    "- Use spaCy to remove puncutation, non-alphanumric data, and elmmatize the text.\n",
    "- Train and apply first-order phrase model to join word pairs (get bigrams).\n",
    "- Train and apply second-order phrase model to join word triplets (get trigrams).\n",
    "- Remove stopwords.\n",
    "- Create tf-idf representations.\n",
    "\n",
    "Useful reference: https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process text\n",
    "process_text(SecReq)\n",
    "process_text(nfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modelling\n",
    "- Learn combinations of tokens that together represents meaningful multi-word phrases (\"United States\", \"happy hour\")\n",
    "- Use gensim to develop phrase models phrase models are developed by examining all the words in The headlines and looking for words that co-occur (i.e., appear one after another) together much more frequently than you would expect them to by random chance.\n",
    "- Once our phrase model has been trained on our corpus, we can apply it to new text. When our model encounters two tokens in new text that identifies as a phrase, it will merge the two into a single new token.\n",
    "\n",
    "Useful reference: https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-7-phrase-modeling-doc2vec-592a8a996867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phraser model, get bigrams\n",
    "model_filepath = \"../models/secreq_bigrams_model\" # bigram model file path for SecReq\n",
    "get_bigrams(SecReq, model_filepath, True)\n",
    "\n",
    "model_filepath = \"../models/nfr_bigrams_model\" # bigram model file path for nfr\n",
    "get_bigrams(nfr, model_filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phraser model, get trigrams\n",
    "model_filepath = \"../models/secreq_trigrams_model\" # bigram model file path for SecReq\n",
    "get_trigrams(SecReq, model_filepath, True)\n",
    "\n",
    "model_filepath = \"../models/nfr_trigrams_model\" # bigram model file path for nfr\n",
    "get_trigrams(nfr, model_filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Multiple identities should be supported within...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[multiple, identity, supported, subscription, ...</td>\n",
       "      <td>[multiple, identity, supported, subscription, ...</td>\n",
       "      <td>[multiple, identity, supported, subscription, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>The CNG shall support both routed and bridged ...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[cng, shall, support, route, bridge, mode, ope...</td>\n",
       "      <td>[cng, shall, support, route, bridge, mode_oper...</td>\n",
       "      <td>[cng, shall, support, route, bridge, mode_oper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>The CNG shall support mechanisms for managing ...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[cng, shall, support, mechanism, manage, iptv,...</td>\n",
       "      <td>[cng, shall, support_mechanism, manage, iptv, ...</td>\n",
       "      <td>[cng, shall_support_mechanism, manage, iptv, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Once an Application becomes the selected Appl...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[application, select, application, basic, logi...</td>\n",
       "      <td>[application, select_application, basic_logica...</td>\n",
       "      <td>[application, select_application_basic_logical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>The Application Provider is responsible for R...</td>\n",
       "      <td>nonsec</td>\n",
       "      <td>[application, provider, responsible, return, r...</td>\n",
       "      <td>[application, provider, responsible, return, r...</td>\n",
       "      <td>[application, provider, responsible, return, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels  \\\n",
       "46   Multiple identities should be supported within...  nonsec   \n",
       "280  The CNG shall support both routed and bridged ...  nonsec   \n",
       "405  The CNG shall support mechanisms for managing ...  nonsec   \n",
       "210   Once an Application becomes the selected Appl...  nonsec   \n",
       "366   The Application Provider is responsible for R...  nonsec   \n",
       "\n",
       "                                        processed_text  \\\n",
       "46   [multiple, identity, supported, subscription, ...   \n",
       "280  [cng, shall, support, route, bridge, mode, ope...   \n",
       "405  [cng, shall, support, mechanism, manage, iptv,...   \n",
       "210  [application, select, application, basic, logi...   \n",
       "366  [application, provider, responsible, return, r...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "46   [multiple, identity, supported, subscription, ...   \n",
       "280  [cng, shall, support, route, bridge, mode_oper...   \n",
       "405  [cng, shall, support_mechanism, manage, iptv, ...   \n",
       "210  [application, select_application, basic_logica...   \n",
       "366  [application, provider, responsible, return, r...   \n",
       "\n",
       "                                              trigrams  \n",
       "46   [multiple, identity, supported, subscription, ...  \n",
       "280  [cng, shall, support, route, bridge, mode_oper...  \n",
       "405  [cng, shall_support_mechanism, manage, iptv, f...  \n",
       "210  [application, select_application_basic_logical...  \n",
       "366  [application, provider, responsible, return, r...  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SecReq.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>8</td>\n",
       "      <td>When streaming a movie  the buffering time sh...</td>\n",
       "      <td>PE</td>\n",
       "      <td>[stream, movie, buffering, time, longer, secon...</td>\n",
       "      <td>[stream_movie, buffering, time, longer_second,...</td>\n",
       "      <td>[stream_movie, buffering, time, longer_second,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>6</td>\n",
       "      <td>The product must make use of web/application ...</td>\n",
       "      <td>O</td>\n",
       "      <td>[product, use, web, application, server, techn...</td>\n",
       "      <td>[product, use, web, application, server, techn...</td>\n",
       "      <td>[product, use, web, application, server, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>11</td>\n",
       "      <td>The system shall have high availability every ...</td>\n",
       "      <td>others</td>\n",
       "      <td>[system, shall, high, availability, day, year,...</td>\n",
       "      <td>[system, shall, high, availability, day, year,...</td>\n",
       "      <td>[system, shall, high, availability, day, year,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>The system will notify affected parties when ...</td>\n",
       "      <td>F</td>\n",
       "      <td>[system, notify, affected, party, change, occu...</td>\n",
       "      <td>[system, notify, affected, party, change, occu...</td>\n",
       "      <td>[system, notify, affected, party, change, occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>The system shall be available for use between ...</td>\n",
       "      <td>others</td>\n",
       "      <td>[system, shall, available, use, hour, p.m.]</td>\n",
       "      <td>[system, shall, available, use, hour, p.m.]</td>\n",
       "      <td>[system, shall, available, use, hour, p.m.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectID                                               text  labels  \\\n",
       "398          8   When streaming a movie  the buffering time sh...      PE   \n",
       "279          6   The product must make use of web/application ...       O   \n",
       "548         11  The system shall have high availability every ...  others   \n",
       "142          3   The system will notify affected parties when ...       F   \n",
       "78           3  The system shall be available for use between ...  others   \n",
       "\n",
       "                                        processed_text  \\\n",
       "398  [stream, movie, buffering, time, longer, secon...   \n",
       "279  [product, use, web, application, server, techn...   \n",
       "548  [system, shall, high, availability, day, year,...   \n",
       "142  [system, notify, affected, party, change, occu...   \n",
       "78         [system, shall, available, use, hour, p.m.]   \n",
       "\n",
       "                                               bigrams  \\\n",
       "398  [stream_movie, buffering, time, longer_second,...   \n",
       "279  [product, use, web, application, server, techn...   \n",
       "548  [system, shall, high, availability, day, year,...   \n",
       "142  [system, notify, affected, party, change, occu...   \n",
       "78         [system, shall, available, use, hour, p.m.]   \n",
       "\n",
       "                                              trigrams  \n",
       "398  [stream_movie, buffering, time, longer_second,...  \n",
       "279  [product, use, web, application, server, techn...  \n",
       "548  [system, shall, high, availability, day, year,...  \n",
       "142  [system, notify, affected, party, change, occu...  \n",
       "78         [system, shall, available, use, hour, p.m.]  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfr.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variant of the nfr dataset in which there are only two classes: functional (F) and non-functional (NF)\n",
    "nfr_binary = nfr.copy()\n",
    "nfr_binary[\"labels\"].replace([\"others\",\"US\",\"SE\",\"O\",\"PE\"], \"NF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels to numeric value\n",
    "encode_label(SecReq)\n",
    "encode_label(nfr)\n",
    "encode_label(nfr_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "secreq_texts = SecReq['trigrams'].astype('str')\n",
    "nfr_texts = nfr_binary_texts = nfr['trigrams'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for the SecReq dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline for modelling**\n",
    "- Convert the transformed text (with trigrams) to a matrix of tf-idf weights (features)\n",
    "- The matrix would contain the tf-idf scores of each token t in each of the document in the corpus.\n",
    "- Perform TruncatedSVD to reduce the number of features-- this is important since our sample size is small, a large feature set will lead to overfitting.\n",
    "- Modelling: use RandomForest and Adaboost\n",
    "- Tune hyperparameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test harness\n",
    "X = secreq_texts\n",
    "y = SecReq['labels_num'].values \n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "models = {\n",
    "    'SVC': SVC(random_state=10),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=10, max_features= \"auto\"),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameters for GridSearchCV\n",
    "# Use a dictionary of dictionaries to set the param grid for each of the models\n",
    "'''\n",
    "SVC:\n",
    "C = the regularization parameter, penalize model complexity\n",
    "gamma = kernel coefficient for ‘rbf’ \n",
    "\n",
    "\n",
    "Random Forest:\n",
    "n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "\n",
    "AdaBoost:\n",
    "n_estimators = number of estimators in the boosted ensemble to use.\n",
    "learning_rate= Learning rate shrinks the contribution of each classifier by learning_rate. \n",
    "'''       \n",
    "\n",
    "params = {\n",
    "    \n",
    "    'SVC':  { \n",
    "        \"clf__C\" : [ 80, 100, 200],\n",
    "        \"clf__gamma\" : [0.05,0.1, 0.15],\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier':  { \n",
    "        \"clf__n_estimators\" : [800, 1000, 1200],\n",
    "        \"clf__max_depth\"      : [20, 30, 40],\n",
    "        \"clf__min_samples_split\" : [3,5,6],\n",
    "        \"clf__min_samples_leaf\" :   [2,3]     \n",
    "    },\n",
    "    \n",
    "    'AdaBoostClassifier':  { \n",
    "        \"clf__n_estimators\" : [250, 500, 600],\n",
    "        \"clf__learning_rate\" : [0.8,1,1.5],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__C': 100, 'clf__gamma': 0.05}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8443834900731453\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__max_depth': 20, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 3, 'clf__n_estimators': 1000}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8009143155694879\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   55.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__learning_rate': 1.5, 'clf__n_estimators': 250}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8420062695924765\n"
     ]
    }
   ],
   "source": [
    "df_secreq_tfidf = models_training(\"SecReq\",\"tfidf\", X_train, y_train, X_test, y_test, models, params, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>wv_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.929701</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.931449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.865492</td>\n",
       "      <td>0.839582</td>\n",
       "      <td>0.849735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SecReq</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.868358</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.816537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset wv_type              model_name  accuracy_score  precision_score  \\\n",
       "0  SecReq   tfidf                     SVC        0.936620         0.929701   \n",
       "2  SecReq   tfidf      AdaBoostClassifier        0.866197         0.865492   \n",
       "1  SecReq   tfidf  RandomForestClassifier        0.845070         0.868358   \n",
       "\n",
       "   recall_score  f1_score  \n",
       "0      0.933312  0.931449  \n",
       "2      0.839582  0.849735  \n",
       "1      0.797242  0.816537  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_secreq_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thoughts:**\n",
    "- I should select SVC since it requires the least training time and it has the best performance (on the test data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for the nfr_binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test harness\n",
    "X = nfr_binary_texts\n",
    "y = nfr_binary['labels_num'].values \n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "models = {\n",
    "    'SVC': SVC(random_state=10),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=10, max_features= \"auto\"),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=10)\n",
    "}\n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "params = {\n",
    "    \n",
    "    'SVC':  { \n",
    "        \"clf__C\" : [50, 100, 200, 300],\n",
    "        \"clf__gamma\" : [0.05,0.1, 0.5, 1, 1.5],\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier':  { \n",
    "        \"clf__n_estimators\" : [200, 800, 1000, 1200],\n",
    "        \"clf__max_depth\"      : [10,30,80,100],\n",
    "        \"clf__min_samples_split\" : [1,2,4],\n",
    "        \"clf__min_samples_leaf\" :   [2,5,10]     \n",
    "    },\n",
    "    \n",
    "    'AdaBoostClassifier':  { \n",
    "        \"clf__n_estimators\" : [100, 500, 800, 1200],\n",
    "        \"clf__learning_rate\" : [0.1,0.5,1,1.5],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__C': 50, 'clf__gamma': 1}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8603970741901776\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__max_depth': 30, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 1000}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8009143155694879\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'clf__learning_rate': 0.1, 'clf__n_estimators': 800}\n",
      "\n",
      "The best accuracy score (on CV) are: 0.8352664576802507\n"
     ]
    }
   ],
   "source": [
    "df_nfr_binary_tfidf = models_training(\"nfr_binary\",\"tfidf\", X_train, y_train, X_test, y_test, models, params, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>wv_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.872517</td>\n",
       "      <td>0.862057</td>\n",
       "      <td>0.866287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.853042</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.813214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfr_binary</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.811198</td>\n",
       "      <td>0.779630</td>\n",
       "      <td>0.787558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset wv_type              model_name  accuracy_score  \\\n",
       "0  nfr_binary   tfidf                     SVC        0.872340   \n",
       "1  nfr_binary   tfidf  RandomForestClassifier        0.829787   \n",
       "2  nfr_binary   tfidf      AdaBoostClassifier        0.803191   \n",
       "\n",
       "   precision_score  recall_score  f1_score  \n",
       "0         0.872517      0.862057  0.866287  \n",
       "1         0.853042      0.802153  0.813214  \n",
       "2         0.811198      0.779630  0.787558  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfr_binary_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
