{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680b9018",
   "metadata": {},
   "source": [
    "# Salary analysis- modelling and performance evaluation\n",
    "- This notebook explores different ways to create models once we have a processed dataframe\n",
    "- We will explore the following:\n",
    "    - Performance evaluation with the validation set approach (train model with no tuning, no CV, just estimate the test performance metric like test rmse with the test set)\n",
    "    - Use k-fold CV to estimate the test performance metric (e.g., mean rmse across all CV folds)\n",
    "    - Use RandomizedSearchCV to identify a set of potential optimal values for the hyperparameter. Refine the tuning with GridSearchCV. Get the mean CV score of the best model. Make predictions with the best model using the test set and get the test metric of the test set.\n",
    "    - Get CV scores of multiple models. We identify the model (amongst a set of models) with the best CV score. Then we only spend time fine-tuning (using GridSearchCV) the model with the best CV score.\n",
    "    - Use GridSearchCV to tune hyperparameters for multiple pipelines (which has the model as the last transformer in the pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fe7e5",
   "metadata": {},
   "source": [
    "## Please place this notebook in the \"notebook\" directory before running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54646a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "'''data'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''visualization'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''sklearn'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''feature engine'''\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OneHotEncoder)\n",
    "\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f610fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory to be one level above /notebook during the INIT RUN \n",
    "try: INIT_RUN\n",
    "except NameError:\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    INIT_RUN=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e577f1",
   "metadata": {},
   "source": [
    "## Project Parameters\n",
    "- Gather all project parameters here, they will be set inside a yaml config file in a future iteration of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac1ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root and data directory of project\n",
    "ROOT_DIR = os.getcwd()\n",
    "RAW_DATA_DIR = Path(ROOT_DIR,\"data\",\"raw\")\n",
    "PROCESSED_DATA_DIR = Path(ROOT_DIR,\"data\",\"processed\")\n",
    "\n",
    "# Selected features\n",
    "FEATURES = [\"age_category\",\"industry\",\"state\",\"city\",\n",
    "            \"overall_experience\",\"in_field_experience\",\n",
    "            \"education\",\"gender\",\"race\"]\n",
    "\n",
    "# Modelling parameters\n",
    "RANDOM = 10\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Custom lower bound for outlier removal\n",
    "OUTLIER_LWR_BOUND = 5000\n",
    "\n",
    "\n",
    "# Data pipeline\n",
    "# Variables that I retain the X most frequent level and lump the rest as \"Other\"\n",
    "CAT_VARS_10_MOST_FREQ = [\"state\",\"city\",\"industry\"]\n",
    "CAT_VARS_2_MOST_FREQ = [\"gender\"]\n",
    "CAT_VARS_4_MOST_FREQ = [\"race\"]\n",
    "\n",
    "# impute missing values with \"missing\"\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = [\"industry\",\"state\",\"city\",\"education\",\"gender\",\"race\"]\n",
    "\n",
    "# variable mappings (string to integer encoding)\n",
    "EXPERIENCE_VARS = [\"overall_experience\",\"in_field_experience\"]\n",
    "AGE_VARS = [\"age_category\"]\n",
    "\n",
    "# one-hot encoding\n",
    "NOMINAL_VARIABLES = [\"industry\",\"state\",\"city\",\"gender\",\"race\",\"education\"]\n",
    "\n",
    "# Fit Gradient boosted tree and random forest models\n",
    "EXECUTE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e6c15",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "- Will be placed in a separate module later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051811c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_get_levels(df,col):\n",
    "    ordered_levels = (df[col]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={'index':'levels'})\n",
    "     # extract the first one (or more) digits\n",
    "    .assign(num_levels=lambda x: x.levels.str.extract(r'(\\d+)').astype(int))\n",
    "    .sort_values(\"num_levels\")\n",
    "    .levels\n",
    "    .tolist())\n",
    "    \n",
    "    # create categorical type\n",
    "    categorical_type =  pd.api.types.CategoricalDtype(\n",
    "    categories=ordered_levels,\n",
    "    ordered=True)\n",
    "    \n",
    "    # convert col to ordered categorical type\n",
    "    df[col] = df[col].astype(categorical_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name, lwr_bound =None, upr_bound=None):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    \n",
    "    if lwr_bound is None:\n",
    "        lwr_bound  = q1-1.5*iqr\n",
    "    \n",
    "    if upr_bound is None:\n",
    "        upr_bound = q3+1.5*iqr\n",
    "    \n",
    "    df_out = df_in.loc[(df_in[col_name] > lwr_bound) & (df_in[col_name] < upr_bound)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e52bc0",
   "metadata": {},
   "source": [
    "### Custom transformer\n",
    "- Map string levels to numeric levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6c5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Categorical variables encoding (the encoding of categorical variables that already have ordered\n",
    "# levels from strings to numeric)\n",
    "\n",
    "class Mapper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Constructor\n",
    "\n",
    "    Args:\n",
    "        variables (List[str]): a list of variables to be recoded (specified by user)\n",
    "        mappings (dict): a dictionary of mappings from old to new encoding\n",
    "\n",
    "    Returns:\n",
    "        void\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, variables, mappings):\n",
    "\n",
    "        # Error handling: check to ensure variables is a list\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "\n",
    "        # Error handling: check to ensure variables is a dict\n",
    "        if not isinstance(mappings, dict):\n",
    "            raise ValueError('mapping should be a dictionary')\n",
    "\n",
    "        # set attributes at instantiation of class\n",
    "        self.variables = variables\n",
    "        self.mappings = mappings\n",
    "\n",
    "    def fit(self, X,\n",
    "            y=None):  # need to have y as argument to make class compatible with sklearn pipeline\n",
    "        \"\"\" Fit\n",
    "\n",
    "        Args:\n",
    "            X (DataFrame): a input dataframe of features to train the transformer\n",
    "            y (DataFrame): a input Series of response variable to train the transformer (optional)\n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # We don't need to learn any parameters for this transformer. Nonetheless, we still need\n",
    "        # to include a fit method so that the Transformer class would be compatible to sklearn\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Transform\n",
    "\n",
    "        Args:\n",
    "            X (DataFrame): a input dataframe of features to be transformed\n",
    "\n",
    "        Returns:\n",
    "            X (DataFrame): the transformed Dataframe of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Make a copy of the input Dataframe of features to be transformed\n",
    "        # so we won't overwrite the original Dataframe that was passed as argument\n",
    "        X = X.copy()\n",
    "\n",
    "        # Perform recoding of the levels of var\n",
    "        for var in self.variables:\n",
    "            X[var] = X[var].map(self.mappings)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd4cc9",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac6f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv(Path(RAW_DATA_DIR,\"survey.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d8cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only focus on respondents (>83% of them) that are paid in USD\n",
    "survey_usd = survey.loc[survey[\"currency\"]=='USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "776fbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables and numeric variables\n",
    "cat_vars = [var for var in survey_usd.columns if survey_usd[var].dtype=='O']\n",
    "num_vars = [var for var in survey_usd.columns if survey_usd[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5873e",
   "metadata": {},
   "source": [
    "## Clean and reformat data\n",
    "- Convert timestamp to datetime\n",
    "- Reformat state, overall_experience, in_field_experience, and age, and convert these variables to ordered categorical variables\n",
    "- Rename variables\n",
    "- Remove outliers (5000,75th percentile+3*IQR)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154630e5",
   "metadata": {},
   "source": [
    "**These are steps that do not have to be included in a data pipeline (does not cause data leakage). Let's implement these steps here.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d92d460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "survey_usd.loc[:,'timestamp'] = survey_usd.loc[:,'timestamp'].astype('datetime64[ns]')\n",
    "\n",
    "# state\n",
    "# Only take the first state in the response and ignore the rest\n",
    "survey_usd[\"state\"]=survey_usd[\"state\"].str.split(',').str[0]\n",
    "\n",
    "# overall_years_of_professional_experience\n",
    "survey_usd['overall_years_of_professional_experience'] = (survey_usd['overall_years_of_professional_experience']\n",
    "                                                      .str\n",
    "                                                      .replace(' - ','-'))\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"overall_years_of_professional_experience\")\n",
    "\n",
    "# years_of_experience_in_field\n",
    "survey_usd['years_of_experience_in_field'] = (survey_usd['years_of_experience_in_field']\n",
    "                                                      .str\n",
    "                                                      .replace(' - ','-'))\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"years_of_experience_in_field\")\n",
    "\n",
    "\n",
    "# age\n",
    "\n",
    "# Need to rename the \"under 18\" level to \"17 or under\" so it can be parsed by the parse_num_get_levels() function\n",
    "survey_usd[\"how_old_are_you\"]=survey_usd[\"how_old_are_you\"].replace(to_replace = \"under 18\",\n",
    "                                                                   value=\"17 or under\")\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"how_old_are_you\")\n",
    "\n",
    "# rename variables\n",
    "survey_usd=survey_usd.rename(columns={\"how_old_are_you\": \"age_category\",\n",
    "                                      \"overall_years_of_professional_experience\":\"overall_experience\",\n",
    "                                      \"years_of_experience_in_field\": \"in_field_experience\",\n",
    "                                      \"highest_level_of_education_completed\":\"education\"},                             \n",
    "                             errors=\"raise\")\n",
    "\n",
    "# Remove outliers\n",
    "survey_usd = remove_outlier(df_in = survey_usd, \n",
    "                            col_name = \"annual_salary\",\n",
    "                            lwr_bound = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e88fe",
   "metadata": {},
   "source": [
    "**Get a dictionary that maps the ordered levels of overall_experience (note: in_field_experience has the same levels) to an integer ordered from (0,number of levels -1). This will be used in the recoding transformer that will be used on overall_experience and in_field_experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709ddb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict(enumerate(survey_usd['overall_experience'].cat.categories))\n",
    "\n",
    "# Set key to value and value to key as per the requirements of \n",
    "# .map() method used in Mapper transformer in preprocessing.py\n",
    "DICT_EXPERIENCE_ORDERED_LEVELS = {v: k for k, v in temp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e17930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 year or less': 0,\n",
       " '2-4 years': 1,\n",
       " '5-7 years': 2,\n",
       " '8-10 years': 3,\n",
       " '11-20 years': 4,\n",
       " '21-30 years': 5,\n",
       " '31-40 years': 6,\n",
       " '41 years or more': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_EXPERIENCE_ORDERED_LEVELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4daeb",
   "metadata": {},
   "source": [
    "**Get a dictionary that maps the ordered levels of age_category to an integer ordered from (0,number of levels -1). This will be used in the Mapper function for age.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa67fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict(enumerate(survey_usd['age_category'].cat.categories))\n",
    "DICT_AGE_ORDERED_LEVELS= {v: k for k, v in temp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e338e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'17 or under': 0,\n",
       " '18-24': 1,\n",
       " '25-34': 2,\n",
       " '35-44': 3,\n",
       " '45-54': 4,\n",
       " '55-64': 5,\n",
       " '65 or over': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_AGE_ORDERED_LEVELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a4f57",
   "metadata": {},
   "source": [
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a71528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16734, 17), (4184, 17))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    survey_usd.drop([\"annual_salary\"], axis=\"columns\"), # features\n",
    "    survey_usd[\"annual_salary\"], # target\n",
    "    test_size = TEST_SIZE,\n",
    "    random_state = RANDOM\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1ff31",
   "metadata": {},
   "source": [
    "**Apply log transformation on DV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19cbcf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75581a9",
   "metadata": {},
   "source": [
    "**Get data subset of selected features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bcfe16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7cc3e",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8a9ba",
   "metadata": {},
   "source": [
    "- We need to impute missing values for 6 features with a new level called \"missing\".\n",
    "- Lump the rare levels of the following categorical variables to \"Other\":\n",
    "    - state\n",
    "    - city\n",
    "    - race \n",
    "    - gender \n",
    "    - industry \n",
    "- Map string encoding to integer encoding for the following ordinal variables:\n",
    "    - overall_experience\n",
    "    - in_field_experience\n",
    "    - age_category\n",
    "- One hot encode nominal features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_pipeline = Pipeline([\n",
    "    \n",
    "    \n",
    "    # === Imputation ===\n",
    "    # Imputing missing values in categorical variables (with a new \"missing\" level)\n",
    "    # CategoricalImputer from feature_engine\n",
    "    ('missing_imputation', CategoricalImputer(imputation_method='missing',\n",
    "                                             variables=CATEGORICAL_VARS_WITH_NA_MISSING)),\n",
    "    \n",
    "    \n",
    "    # === Recoding categorical variables ===\n",
    "    (\"rare_label_encoder_10\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 10,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_10_MOST_FREQ)),\n",
    "    \n",
    "    (\"rare_label_encoder_2\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 2,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_2_MOST_FREQ)),\n",
    "    \n",
    "    (\"rare_label_encoder_4\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 4,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_4_MOST_FREQ)),\n",
    "    \n",
    "    # === Recoding categorical variables with ordered level ===\n",
    "    \n",
    "    # Recode categorical variables with ordered level: map from string encoding to numeric encoding\n",
    "    # Use custom class from 'preprocessing.py' Mappers\n",
    "    ('mapper_exp',Mapper(\n",
    "        variables=EXPERIENCE_VARS, mappings=DICT_EXPERIENCE_ORDERED_LEVELS)),\n",
    "\n",
    "    ('mapper_age', Mapper(\n",
    "        variables=AGE_VARS, mappings=DICT_AGE_ORDERED_LEVELS)),\n",
    "    \n",
    "     # === One-hot enccode nominal variables ===\n",
    "    ('one_hot_encoder', OneHotEncoder(drop_last=True, # avoid dummy variable trap\n",
    "                                      variables = NOMINAL_VARIABLES))\n",
    "    \n",
    "\n",
    "])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a18c20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;missing_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;,\n",
       "                                               &#x27;education&#x27;, &#x27;gender&#x27;,\n",
       "                                               &#x27;race&#x27;])),\n",
       "                (&#x27;rare_label_encoder_10&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with=&#x27;Other&#x27;, tol=0.01,\n",
       "                                  variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])),\n",
       "                (&#x27;rare_label_encoder_2&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                                  &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "                        variables=[&#x27;overall_experience&#x27;,\n",
       "                                   &#x27;in_field_experience&#x27;])),\n",
       "                (&#x27;mapper_age&#x27;,\n",
       "                 Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2,\n",
       "                                  &#x27;35-44&#x27;: 3, &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5,\n",
       "                                  &#x27;65 or over&#x27;: 6},\n",
       "                        variables=[&#x27;age_category&#x27;])),\n",
       "                (&#x27;one_hot_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;,\n",
       "                                          &#x27;race&#x27;, &#x27;education&#x27;]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;missing_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;,\n",
       "                                               &#x27;education&#x27;, &#x27;gender&#x27;,\n",
       "                                               &#x27;race&#x27;])),\n",
       "                (&#x27;rare_label_encoder_10&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with=&#x27;Other&#x27;, tol=0.01,\n",
       "                                  variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])),\n",
       "                (&#x27;rare_label_encoder_2&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                                  &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "                        variables=[&#x27;overall_experience&#x27;,\n",
       "                                   &#x27;in_field_experience&#x27;])),\n",
       "                (&#x27;mapper_age&#x27;,\n",
       "                 Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2,\n",
       "                                  &#x27;35-44&#x27;: 3, &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5,\n",
       "                                  &#x27;65 or over&#x27;: 6},\n",
       "                        variables=[&#x27;age_category&#x27;])),\n",
       "                (&#x27;one_hot_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;,\n",
       "                                          &#x27;race&#x27;, &#x27;education&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;education&#x27;,\n",
       "                              &#x27;gender&#x27;, &#x27;race&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=10, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=2, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;gender&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=4, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;race&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Mapper</label><div class=\"sk-toggleable__content\"><pre>Mapper(mappings={&#x27;1 year or less&#x27;: 0, &#x27;11-20 years&#x27;: 4, &#x27;2-4 years&#x27;: 1,\n",
       "                 &#x27;21-30 years&#x27;: 5, &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                 &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "       variables=[&#x27;overall_experience&#x27;, &#x27;in_field_experience&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Mapper</label><div class=\"sk-toggleable__content\"><pre>Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2, &#x27;35-44&#x27;: 3,\n",
       "                 &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5, &#x27;65 or over&#x27;: 6},\n",
       "       variables=[&#x27;age_category&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True,\n",
       "              variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;, &#x27;race&#x27;,\n",
       "                         &#x27;education&#x27;])</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('missing_imputation',\n",
       "                 CategoricalImputer(variables=['industry', 'state', 'city',\n",
       "                                               'education', 'gender',\n",
       "                                               'race'])),\n",
       "                ('rare_label_encoder_10',\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with='Other', tol=0.01,\n",
       "                                  variables=['state', 'city', 'industry'])),\n",
       "                ('rare_label_encoder_2',\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  '31-40 years': 6, '41 years or more': 7,\n",
       "                                  '5-7 years': 2, '8-10 years': 3},\n",
       "                        variables=['overall_experience',\n",
       "                                   'in_field_experience'])),\n",
       "                ('mapper_age',\n",
       "                 Mapper(mappings={'17 or under': 0, '18-24': 1, '25-34': 2,\n",
       "                                  '35-44': 3, '45-54': 4, '55-64': 5,\n",
       "                                  '65 or over': 6},\n",
       "                        variables=['age_category'])),\n",
       "                ('one_hot_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['industry', 'state', 'city', 'gender',\n",
       "                                          'race', 'education']))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline to train data\n",
    "salary_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe176f",
   "metadata": {},
   "source": [
    "## Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8478b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and X_test with the fitted pipeline\n",
    "X_train = salary_pipeline.transform(X_train)\n",
    "X_test = salary_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = X_train.columns.values # save the column names of the processed X_train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86206392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed X_train, X_test, y_train and y_test\n",
    "X_train.to_csv(Path(PROCESSED_DATA_DIR,\"X_train.csv\"))\n",
    "X_test.to_csv(Path(PROCESSED_DATA_DIR,\"X_test.csv\"))\n",
    "\n",
    "y_train.to_csv(Path(PROCESSED_DATA_DIR,\"y_train.csv\"))\n",
    "y_test.to_csv(Path(PROCESSED_DATA_DIR,\"y_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ed14e",
   "metadata": {},
   "source": [
    "## Up to this point, all the code is same as \"02-salary_survey_analysis\" notebook. From this point on, we will explore different ways to train and evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28517a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9015662",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74438637",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''models'''\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "'''performance evaluation'''\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "'''others'''\n",
    "from random import sample # randomly sample elements from a list\n",
    "import joblib # persist models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02331c36",
   "metadata": {},
   "source": [
    "## 00- Baseline model\n",
    "- A naive guess of what the employee salary are. We make the same predictions for each employee-- the median salary across all employees in the train (and test) data.\n",
    "- Having a baseline prediction will allow us to see how much of an improvement I can get if I use an statistical learning approach. If the improvement is very small, then perhaps statistical learning is not a suitable approach for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eae2f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "       ...    \n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "Length: 4184, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_pred = np.median(np.log(survey_usd[\"annual_salary\"]))\n",
    "# make this into a pd.Series with the same length as y_test\n",
    "y_pred_baseline = pd.Series(baseline_pred).repeat(y_test.shape[0])\n",
    "y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae053bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of the baseline model is 0.47\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rmse of the baseline model is {round(mean_squared_error(y_test,y_pred_baseline, squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454ccd5",
   "metadata": {},
   "source": [
    "**Alternatively, use sklearn.DummyRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2c05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor(strategy=&#x27;median&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor(strategy='median')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init the dummy regressor\n",
    "dummy_regr = DummyRegressor(strategy=\"median\")\n",
    "# Train the model\n",
    "dummy_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51e82c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of the baseline model is 0.47.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and get baseline performance\n",
    "y_pred_baseline=dummy_regr.predict(X_test)\n",
    "print(f\"The rmse of the baseline model is {round(mean_squared_error(y_test,y_pred_baseline, squared=False),2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0299e9",
   "metadata": {},
   "source": [
    "## 1.1 Linear regression model with no tuning (validation approach)\n",
    "- Linear regression model\n",
    "- Evaluate model performance with the validation set approach: estimate the test metric using the test (aka validation) set.\n",
    "- In general, rather than calculating multiple metrics and trying to determine how important each one is, we should use a single metric. Except for the Linear regression model, henceforth, we will use rmse as our evaluation metric.\n",
    "    - NOTE: RMSE (aka SER): provides the absolute measure of the \"typical distance\" that the data points fall from the regression line. It is in the units of the dependent variable.\n",
    "    - Interpretation of RMSE or MAE if the dependent variable is log transformed: it is (roughly) the typical percentage deviation away from the geometric mean of the DV, conditional on the IVs\n",
    "    - https://stats.stackexchange.com/questions/314490/regression-rmse-when-dependent-variable-is-log-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b35e4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Train model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# use the trained model to predict log employee salary from X_test\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e683d074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.16440194, 11.52152978, 10.84067777, ..., 11.28744253,\n",
       "       11.87515363, 11.21895769])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8cce6d",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3af53774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the estimated test metrics using validation set approach\n",
    "rmse = round(mean_squared_error(y_test,y_pred,squared=False),2)\n",
    "mae= round(mean_absolute_error(y_test, y_pred),2)\n",
    "r2 = round(r2_score(y_test,y_pred),2)\n",
    "r2_adj = round(1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd7db830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rmse: 0.36 \n",
      " mae: 0.27 \n",
      " r2: 0.41 \n",
      " r2_adj: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(f\" rmse: {rmse} \\n mae: {mae} \\n r2: {r2} \\n r2_adj: {r2_adj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12704e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/hfung/Documents/PycharmProjects/practice_projects/salary_survey_analysis/models/linear_regression.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist model\n",
    "joblib.dump(reg, Path(ROOT_DIR,\"models\",\"linear_regression.joblib\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f2869",
   "metadata": {},
   "source": [
    "**The typical percentage deviation of each data point from the geometric mean of annual salary is 100*(1-exp(0.36)) = 43%, which is lower than the baseline model (60% deviation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee059039",
   "metadata": {},
   "source": [
    "## 1.2 Linear regression model with no tuning (k-fold CV)\n",
    "- To get a better estimate of the test metric (with less bias and variance), we use 10-fold cross validation.\n",
    "- Randomly divide train observations into k folds of equal size. Use one fold as the test set and the remaining folds as the train set. Compute rmse.\n",
    "- Repeat this k times until all k folds are used as the test set. I have k rmse (aka CV scores).\n",
    "- Compute the mean CV score across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d944bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CV rmse for each fold\n",
    "l_cv_rmse = cross_val_score(\n",
    "    estimator = LinearRegression(),\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = 10,\n",
    "    scoring = \"neg_root_mean_squared_error\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b66409c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35668112, -0.34845976, -0.35222272, -0.35747606, -0.36471218,\n",
       "       -0.34201147, -0.34826188, -0.3625287 , -0.35697226, -0.35543842])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See below for more details as to why the values are -ve\n",
    "l_cv_rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "813030f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse = round(l_cv_rmse.mean(),2)\n",
    "cv_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b40341",
   "metadata": {},
   "source": [
    "## 1.3 LASSO regression model with tuning (RandomSearchCV)\n",
    "- We have a grid of values for lambda (aka alpha)\n",
    "- We randomly sample X lambdas from this grid, and then train a model for each lambda and obtain its mean CV score.\n",
    "- For each value of lambda in the grid, we compute the estimated test metric from CV:\n",
    "    - Divide the train data into 10 parts, use 9 parts to train, 1 part to test, and set lambda = 0.01 (assuming this is the current lambda in the grid that we are using).\n",
    "    - Repeat this for each fold. In the end we get cv_rmse_1,...,cv_rmse_10\n",
    "    - Take the mean and we get the cv_rmse for lambda=0.1 \n",
    "- Repeat this for each randomly selected lambda from the grid. For each model (lambda), we get a cv_rmse. \n",
    "- We choose the best lambda* that produces a model with the smallest cv_rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab107869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04948979591836735,\n",
       " 0.06161224489795919,\n",
       " 0.02928571428571429,\n",
       " 0.059591836734693884,\n",
       " 0.01716326530612245,\n",
       " 0.07171428571428572,\n",
       " 0.035346938775510206,\n",
       " 0.0030204081632653063,\n",
       " 0.03938775510204082,\n",
       " 0.0636326530612245]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a range of alphas to try\n",
    "# get 50 evenly spaced values between 0.001 and 0.1 \n",
    "_alpha = [x for x in np.linspace(start = 0.001, stop = 0.1, num = 50)] \n",
    "sample(_alpha,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8154e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid\n",
    "random_grid = {'alpha': _alpha}\n",
    "# init the model\n",
    "reg= Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8151957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search of the parameters, using a 10 fold CV to estimate the test metric for each setting.\n",
    "rand_grid_search = RandomizedSearchCV(estimator = reg,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 20,  # randomly select 20 different settings to try\n",
    "                                cv = 10,       # use 10-fold CV for each setting to estimate its test metric\n",
    "                                scoring=\"neg_root_mean_squared_error\",\n",
    "                                verbose = 1, #2   # show the process\n",
    "                                n_jobs =-1,  # use all processors\n",
    "                                random_state = RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e18de636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=Lasso(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.001, 0.0030204081632653063,\n",
       "                                                  0.0050408163265306125,\n",
       "                                                  0.007061224489795919,\n",
       "                                                  0.009081632653061226,\n",
       "                                                  0.011102040816326531,\n",
       "                                                  0.013122448979591837,\n",
       "                                                  0.015142857142857145,\n",
       "                                                  0.01716326530612245,\n",
       "                                                  0.019183673469387756,\n",
       "                                                  0.02120408163265306,\n",
       "                                                  0.02322448979591837,\n",
       "                                                  0.025244897959183676,...\n",
       "                                                  0.0333265306122449,\n",
       "                                                  0.035346938775510206,\n",
       "                                                  0.03736734693877551,\n",
       "                                                  0.03938775510204082,\n",
       "                                                  0.04140816326530612,\n",
       "                                                  0.043428571428571434,\n",
       "                                                  0.04544897959183674,\n",
       "                                                  0.047469387755102045,\n",
       "                                                  0.04948979591836735,\n",
       "                                                  0.051510204081632656,\n",
       "                                                  0.05353061224489796,\n",
       "                                                  0.05555102040816327,\n",
       "                                                  0.05757142857142858,\n",
       "                                                  0.059591836734693884, ...]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=Lasso(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.001, 0.0030204081632653063,\n",
       "                                                  0.0050408163265306125,\n",
       "                                                  0.007061224489795919,\n",
       "                                                  0.009081632653061226,\n",
       "                                                  0.011102040816326531,\n",
       "                                                  0.013122448979591837,\n",
       "                                                  0.015142857142857145,\n",
       "                                                  0.01716326530612245,\n",
       "                                                  0.019183673469387756,\n",
       "                                                  0.02120408163265306,\n",
       "                                                  0.02322448979591837,\n",
       "                                                  0.025244897959183676,...\n",
       "                                                  0.0333265306122449,\n",
       "                                                  0.035346938775510206,\n",
       "                                                  0.03736734693877551,\n",
       "                                                  0.03938775510204082,\n",
       "                                                  0.04140816326530612,\n",
       "                                                  0.043428571428571434,\n",
       "                                                  0.04544897959183674,\n",
       "                                                  0.047469387755102045,\n",
       "                                                  0.04948979591836735,\n",
       "                                                  0.051510204081632656,\n",
       "                                                  0.05353061224489796,\n",
       "                                                  0.05555102040816327,\n",
       "                                                  0.05757142857142858,\n",
       "                                                  0.059591836734693884, ...]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=Lasso(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.001, 0.0030204081632653063,\n",
       "                                                  0.0050408163265306125,\n",
       "                                                  0.007061224489795919,\n",
       "                                                  0.009081632653061226,\n",
       "                                                  0.011102040816326531,\n",
       "                                                  0.013122448979591837,\n",
       "                                                  0.015142857142857145,\n",
       "                                                  0.01716326530612245,\n",
       "                                                  0.019183673469387756,\n",
       "                                                  0.02120408163265306,\n",
       "                                                  0.02322448979591837,\n",
       "                                                  0.025244897959183676,...\n",
       "                                                  0.0333265306122449,\n",
       "                                                  0.035346938775510206,\n",
       "                                                  0.03736734693877551,\n",
       "                                                  0.03938775510204082,\n",
       "                                                  0.04140816326530612,\n",
       "                                                  0.043428571428571434,\n",
       "                                                  0.04544897959183674,\n",
       "                                                  0.047469387755102045,\n",
       "                                                  0.04948979591836735,\n",
       "                                                  0.051510204081632656,\n",
       "                                                  0.05353061224489796,\n",
       "                                                  0.05555102040816327,\n",
       "                                                  0.05757142857142858,\n",
       "                                                  0.059591836734693884, ...]},\n",
       "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "rand_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da2896",
   "metadata": {},
   "source": [
    "**NOTE: Why rmse is negative when used in model tuning functions (need to specify 'neg_root_mean_squared_error' in : RandomizeSearchCV, GridSearchCV, and cross_val_score), but positive when I just use mean_squared_error(y_true, y_pred)?**\n",
    "- **Please see link for more details:** https://stackoverflow.com/questions/48244219/is-sklearn-metrics-mean-squared-error-the-larger-the-better-negated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3113731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean CV score (rmse) of the best estimator is: 0.37096963715122805\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean CV score (rmse) of the best estimator is: {-rand_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6acd1aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha for the LASSO model from RandomGridSearch is {'alpha': 0.0050408163265306125}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best alpha for the LASSO model from RandomGridSearch is {rand_grid_search.best_params_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4ef3a",
   "metadata": {},
   "source": [
    "I should hone in and fine-tune alpha by defining a grid of alphas that have very small values. I would then compute the CV score for this set of smaller alphas and find the optimal one using GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0a564",
   "metadata": {},
   "source": [
    "## 1.4 LASSO regression model with tuning (GridSearchCV)\n",
    "- We have a user defined grid of values for lambda (aka alpha)\n",
    "- For each value of lambda in the grid, we compute the estimated test metric from CV:\n",
    "    - Divide the train data into 10 parts, use 9 parts to train, 1 part to test, and setting lambda = 0.1 (assuming this is the current lambda in the grid that we are using).\n",
    "    - Repeat this for each fold. In the end we get cv_rmse_1,...,cv_rmse_10\n",
    "    - Take the mean and we get the cv_rmse for lambda=0.1 \n",
    "- Repeat this for all lambdas in the grid. For each model (lambda in the grid), we get a cv_rmse. \n",
    "- We choose the best lambda* that produces a model with the smallest cv_rmse.\n",
    "- Using this lambda*, we use the full train dataset to train a final \"best model\" (this is done automatically by GridSearchCV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d28746ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.001,\n",
       "  0.002,\n",
       "  0.003,\n",
       "  0.004,\n",
       "  0.005,\n",
       "  0.006,\n",
       "  0.007,\n",
       "  0.008,\n",
       "  0.009000000000000001]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init model\n",
    "reg = Lasso()\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\"alpha\":list(np.arange(0.001,0.01, 0.001))}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ccb83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           scoring=\"neg_root_mean_squared_error\",\n",
    "                           verbose =1, # show the process\n",
    "                           n_jobs = -1)  # n_jobs = -1 means use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55f1cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009000000000000001]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009000000000000001]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009000000000000001]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "920ef9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameter from GridSearchCV is: {'alpha': 0.001}\n",
      "\n",
      "The mean CV score (rmse) of the model with the best parameter is: 0.35726026819675716\n"
     ]
    }
   ],
   "source": [
    "# The optimal parameter\n",
    "print(f\"The optimal parameter from GridSearchCV is: {grid_search.best_params_}\")\n",
    "\n",
    "# The score of the model with the optimal parameter\n",
    "print(f\"\\nThe mean CV score (rmse) of the model with the best parameter is: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "970a142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model that uses the \"best\" hp, trained from the full train set\n",
    "best_reg = grid_search.best_estimator_\n",
    "# Make predictions using X_test\n",
    "y_pred = best_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4eaaa0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test rmse of the tuned model estimated using the test set is: 0.36\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model (rmse) with the test set\n",
    "print(f\"The test rmse of the tuned model estimated using the test set is: {round(mean_squared_error(y_test,y_pred,squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd9f7a",
   "metadata": {},
   "source": [
    "**The fact that a very small alpha 0.001 has a lower performance (higher rmse) than the unregularized linear regression model suggest that all included regressors are important in predicting salary. I should use LinearRegression with no regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a5d33",
   "metadata": {},
   "source": [
    "## 2.1 Using multiple statistical approaches (no tuning, k-fold CV)\n",
    "- We will train a linear regression model, gradient boosted regressor, and random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79f7cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to test\n",
    "def get_models():\n",
    "    # init list of models with associated names\n",
    "    models,names = list(), list()\n",
    "    \n",
    "    # linear regression\n",
    "    models.append(LinearRegression())\n",
    "    names.append(\"linear_regression\")\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    models.append(RandomForestRegressor())\n",
    "    names.append(\"random_forest\")\n",
    "    \n",
    "    # Gradient Boosted Trees\n",
    "    models.append(GradientBoostingRegressor())\n",
    "    names.append(\"gradient_boosting\")\n",
    "    \n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b62152a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a model with k-fold cross validation\n",
    "def evaluate_model(X,y,model):\n",
    "    scores = cross_val_score(\n",
    "        estimator = model,\n",
    "        X = X,\n",
    "        y = y,\n",
    "        cv = 10,\n",
    "        scoring = \"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb475b",
   "metadata": {},
   "source": [
    "**Initiate models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82732ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, names = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9c056ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([LinearRegression(), RandomForestRegressor(), GradientBoostingRegressor()],\n",
       " ['linear_regression', 'random_forest', 'gradient_boosting'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a88958",
   "metadata": {},
   "source": [
    "**Evaluate models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48d1d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear_regression', 0.35, 0.01)\n",
      "('random_forest', 0.38, 0.01)\n",
      "('gradient_boosting', 0.36, 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model (get estimated test metric) and store the results in a list \"l_mean_cv_scores\"\n",
    "l_cv_scores = list()\n",
    "for model, name in list(zip(models, names)):\n",
    "    \n",
    "    # Compute cv scores of each model\n",
    "    cv_scores = evaluate_model(X_train, y_train, model)\n",
    "    \n",
    "    # Update the list of model results, each row represent the cv scores of a model\n",
    "    l_cv_scores.append(cv_scores)\n",
    "\n",
    "    # Summary of model performance\n",
    "    print((name, round(-cv_scores.mean(),2), round(np.std(cv_scores),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5050ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative rmse')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.boxplot(l_cv_scores, labels=names, showmeans=True)\n",
    "plt.ylabel(\"negative rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef9f23",
   "metadata": {},
   "source": [
    "- Linear regression model has the best performance-- it has the least rmse (average percent deviation of data from geometric mean of annual salary across all train observations)\n",
    "- We can tune random forest and gradient boosting to see if the tuned models can outperform linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea0b49",
   "metadata": {},
   "source": [
    "## 2.2 Using multiple statistical approaches (with hyperparameter tuning)\n",
    "- Here, I will tune both the random forest and gradient boosted tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210dc2c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9852b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfff63",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV for Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63b48572",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "   \"n_estimators\": [10, 100, 1000],\n",
    "    \"max_features\": ['sqrt','log2'],\n",
    "    \"max_depth\": [None,1,3,10,40,50],\n",
    "    \"min_samples_split\": [2,5,10,50,100],\n",
    "    \"min_samples_leaf\": [2,5,10,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a73e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search of the parameters, using a 10 fold CV to estimate the test metric for each setting.\n",
    "rand_grid_search = RandomizedSearchCV(estimator = reg,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 20,  # randomly select 20 different settings to try\n",
    "                                cv = 10,       # use 10-fold CV for each setting to estimate its test metric\n",
    "                                scoring=\"neg_root_mean_squared_error\",\n",
    "                                verbose = 1, #2   # show the process\n",
    "                                n_jobs =-1,  # use all processors\n",
    "                                random_state = RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56625df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 1, 3, 10, 40, 50],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 5, 10, 50, 100],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 1, 3, 10, 40, 50],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 5, 10, 50, 100],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 1, 3, 10, 40, 50],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [2, 5, 10, 50, 100],\n",
       "                                        'min_samples_split': [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        'n_estimators': [10, 100, 1000]},\n",
       "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4cc73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean CV score (rmse) of the best estimator is: 0.35709661135510834\n",
      "The best alpha for the rf model from RandomGridSearch is {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean CV score (rmse) of the best estimator is: {-rand_grid_search.best_score_}\")\n",
    "print(f\"The best alpha for the rf model from RandomGridSearch is {rand_grid_search.best_params_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ad231",
   "metadata": {},
   "source": [
    "**GridSearchCV for Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1845705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=1000,\n",
    "                           max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42360204",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [35,40,45],\n",
    "    \"min_samples_split\": [4,5,6],\n",
    "    \"min_samples_leaf\": [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6be085c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           scoring=\"neg_root_mean_squared_error\",\n",
    "                           verbose =1, # show the process\n",
    "                           n_jobs = -1)  # n_jobs = -1 means use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdd481cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "The optimal parameter from GridSearchCV is: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 6}\n",
      "\n",
      "The mean CV score (rmse) of the model with the best parameter is: 0.3568170638312602\n",
      "The test rmse of the tuned model estimated using the test set is: 0.36\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    \n",
    "    # The optimal parameter\n",
    "    print(f\"The optimal parameter from GridSearchCV is: {grid_search.best_params_}\")\n",
    "\n",
    "    # The score of the model with the optimal parameter\n",
    "    print(f\"\\nThe mean CV score (rmse) of the model with the best parameter is: {-grid_search.best_score_}\")\n",
    "    \n",
    "    # Get the model that uses the \"best\" hp, trained from the full train set\n",
    "    best_reg = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions using X_test\n",
    "    y_pred = best_reg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance of the model (rmse) with the test set\n",
    "    print(f\"The test rmse of the tuned model estimated using the test set is: {round(mean_squared_error(y_test,y_pred,squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b937fca",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2ca359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e4cb7",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV for gb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b931e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "   \"n_estimators\": [100, 500, 1000], # number of trees to build\n",
    "   \"learning_rate\": [0.01,0.05,0.1], # learning rate\n",
    "   \"max_depth\":[4,6,8,10], # maximum depth of each tree\n",
    "   \"subsample\":[0.5,0.75,1.0], # prop of train set (observations) to consider for each tree\n",
    "   \"max_features\":[0.4,0.6,0.8,1.0] # prop of features to consider for each split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f350f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search of the parameters, using a 10 fold CV to estimate the test metric for each setting.\n",
    "rand_grid_search = RandomizedSearchCV(estimator = reg,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 20,  # randomly select 20 different settings to try\n",
    "                                cv = 10,       # use 10-fold CV for each setting to estimate its test metric\n",
    "                                scoring=\"neg_root_mean_squared_error\",\n",
    "                                verbose = 1, #2   # show the process\n",
    "                                n_jobs =-1,  # use all processors\n",
    "                                random_state = RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d28a604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                                        &#x27;max_features&#x27;: [0.4, 0.6, 0.8, 1.0],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                                        &#x27;max_features&#x27;: [0.4, 0.6, 0.8, 1.0],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1],\n",
       "                                        'max_depth': [4, 6, 8, 10],\n",
       "                                        'max_features': [0.4, 0.6, 0.8, 1.0],\n",
       "                                        'n_estimators': [100, 500, 1000],\n",
       "                                        'subsample': [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff883006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean CV score (rmse) of the best estimator is: 0.350999775450384\n",
      "The best alpha for the gb model from RandomGridSearch is {'subsample': 1.0, 'n_estimators': 1000, 'max_features': 0.4, 'max_depth': 4, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean CV score (rmse) of the best estimator is: {-rand_grid_search.best_score_}\")\n",
    "print(f\"The best alpha for the gb model from RandomGridSearch is {rand_grid_search.best_params_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6736ab",
   "metadata": {},
   "source": [
    "**GridSearchCV for Gradient Boosted trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0d96744",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=1000,\n",
    "                                subsample=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ee22a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\":[0.02,0.05,0.08],\n",
    "    \"max_depth\": [3,4,5],\n",
    "    \"max_features\": [0.3,0.4,0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c0b41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           scoring=\"neg_root_mean_squared_error\",\n",
    "                           verbose =1, # show the process\n",
    "                           n_jobs = -1)  # n_jobs = -1 means use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "904cbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "The optimal parameter from GridSearchCV is: {'learning_rate': 0.08, 'max_depth': 3, 'max_features': 0.3}\n",
      "\n",
      "The mean CV score (rmse) of the model with the best parameter is: 0.35038119618826086\n",
      "The test rmse of the tuned model estimated using the test set is: 0.35\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    \n",
    "    # The optimal parameter\n",
    "    print(f\"The optimal parameter from GridSearchCV is: {grid_search.best_params_}\")\n",
    "\n",
    "    # The score of the model with the optimal parameter\n",
    "    print(f\"\\nThe mean CV score (rmse) of the model with the best parameter is: {-grid_search.best_score_}\")\n",
    "    \n",
    "    # Get the model that uses the \"best\" hp, trained from the full train set\n",
    "    best_reg = grid_search.best_estimator_\n",
    "    # Make predictions using X_test\n",
    "    y_pred = best_reg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance of the model (rmse) with the test set\n",
    "    print(f\"The test rmse of the tuned model estimated using the test set is: {round(mean_squared_error(y_test,y_pred,squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81044f",
   "metadata": {},
   "source": [
    "**By tuning hyperparameters, the performance of random forest and gb is close to linear regression model (close to 0.35). However, since linear regression has fast training time and interpretible, we will use linear regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1632ce0",
   "metadata": {},
   "source": [
    "## 3.1 Using multiple statistical approaches with data processing pipeline and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9110a9",
   "metadata": {},
   "source": [
    "### Test harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c414de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16734, 17), (4184, 17))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    survey_usd.drop([\"annual_salary\"], axis=\"columns\"), # features\n",
    "    survey_usd[\"annual_salary\"], # target\n",
    "    test_size = TEST_SIZE,\n",
    "    random_state = RANDOM\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74178fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99338986",
   "metadata": {},
   "source": [
    "**A list of models to tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "812ea7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=1000,\n",
    "                                            max_features=\"sqrt\"),\n",
    "    \"gradient_boosting\": GradientBoostingRegressor(n_estimators=1000,\n",
    "                                               subsample=1.0)    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ddefa",
   "metadata": {},
   "source": [
    "**Hyperparameters for data processing steps in pipeline (if any) and for each model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3d371b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict of dicts\n",
    "param_grid = {\n",
    "    # == random forest ==\n",
    "    \"random_forest\": {\n",
    "        \"regressor__max_depth\": [35,40,45],\n",
    "        \"regressor__min_samples_split\":[4,5,6],\n",
    "        \"regressor__min_samples_leaf\":[1,2,3]    \n",
    "    },\n",
    "    # == gradient boosting ==\n",
    "    \"gradient_boosting\":{\n",
    "        \"regressor__learning_rate\": [0.02,0.05,0.08],\n",
    "        \"regressor__max_depth\": [3,4,5],\n",
    "        \"regressor__max_features\": [0.3,0.4,0.5]        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10137116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    results=[] # init a list that contains results for each model\n",
    "\n",
    "    for model_name in models.keys():\n",
    "       \n",
    "        # append current model to pipeline as the last step (ex: 'regressor, RandomForestRegressor()')\n",
    "        salary_pipeline.steps.append(['regressor', models[model_name]])\n",
    "    \n",
    "        # Get the params for the current model\n",
    "        params = param_grid[model_name]\n",
    "    \n",
    "        # Init GridSearchCV \n",
    "        grid = GridSearchCV(estimator = salary_pipeline, \n",
    "                            param_grid = params, \n",
    "                            cv = 5, \n",
    "                            scoring=\"neg_root_mean_squared_error\",\n",
    "                            verbose =1, # show the process\n",
    "                            n_jobs = -1)  # n_jobs = -1 means use all processors    \n",
    "    \n",
    "        # Fit GridSearchCV\n",
    "        grid.fit(X_train, y_train)\n",
    "    \n",
    "        # remove last step (model) of the pipeline so it can be reused for the next iter (model)\n",
    "        salary_pipeline=salary_pipeline[:-1]\n",
    "    \n",
    "        # Collect results of GridSearchCV\n",
    "        results.append({\n",
    "            'model_name': model_name,\n",
    "            'grid': grid,\n",
    "            'best_estimator': grid.best_estimator_,\n",
    "            'best_score': grid.best_score_,\n",
    "            'best_params': grid.best_params_\n",
    "        })\n",
    "        \n",
    "        # Persist model\n",
    "        joblib.dump(grid.best_estimator_,Path(ROOT_DIR,\"models\",f\"{model_name}.joblib\"))\n",
    "\n",
    "    # Look at results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = (df_results\n",
    "                  .rename(df_results[\"model_name\"],axis=\"index\"))\n",
    "    df_results[\"best_score\"] = -1*df_results[\"best_score\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "845f6b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>grid</th>\n",
       "      <th>best_estimator</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>(CategoricalImputer(variables=['industry', 'st...</td>\n",
       "      <td>0.357079</td>\n",
       "      <td>{'regressor__max_depth': 35, 'regressor__min_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>(CategoricalImputer(variables=['industry', 'st...</td>\n",
       "      <td>0.351140</td>\n",
       "      <td>{'regressor__learning_rate': 0.05, 'regressor_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model_name  \\\n",
       "random_forest          random_forest   \n",
       "gradient_boosting  gradient_boosting   \n",
       "\n",
       "                                                                grid  \\\n",
       "random_forest      GridSearchCV(cv=5,\\n             estimator=Pip...   \n",
       "gradient_boosting  GridSearchCV(cv=5,\\n             estimator=Pip...   \n",
       "\n",
       "                                                      best_estimator  \\\n",
       "random_forest      (CategoricalImputer(variables=['industry', 'st...   \n",
       "gradient_boosting  (CategoricalImputer(variables=['industry', 'st...   \n",
       "\n",
       "                   best_score  \\\n",
       "random_forest        0.357079   \n",
       "gradient_boosting    0.351140   \n",
       "\n",
       "                                                         best_params  \n",
       "random_forest      {'regressor__max_depth': 35, 'regressor__min_s...  \n",
       "gradient_boosting  {'regressor__learning_rate': 0.05, 'regressor_...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b4ef",
   "metadata": {},
   "source": [
    "**Both the tuned random forest and gradient boosting have a similar rmse to the linear regression model (0.35). The performance (rmse) is not very different across the three model. Due to the simplicity, low training time and computational requirement, and interpretibility of the linear regression model, I will select this model for this problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23bd02",
   "metadata": {},
   "source": [
    "## 4.1 Feature importance from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "689d70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best random forest model pipeline\n",
    "best_rf_pipeline=joblib.load(Path(ROOT_DIR,\"models\",\"random_forest.joblib\"))\n",
    "# Get best random forest model\n",
    "best_rf= best_rf_pipeline.named_steps[\"regressor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90c7b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature importances into a dataframe\n",
    "feature_results = pd.DataFrame({'feature': feature_columns, \n",
    "                                'importance': best_rf.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c616850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance from random forest'}, ylabel='relative feature importance'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "(feature_results\n",
    "     .sort_values(\"importance\", ascending=False)\n",
    "     .set_index(\"feature\")\n",
    "     .head(10)\n",
    "     .plot.barh(\n",
    "         ax=ax,\n",
    "         color='k',\n",
    "         alpha=0.7,\n",
    "         title=\"Feature importance from random forest\",\n",
    "         xlabel=\"relative feature importance\",\n",
    "         ylabel=\"features\"         \n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9218eda",
   "metadata": {},
   "source": [
    "**There are only a few important determinants of annual salary (from random forest model): being in the computing or tech industry, years of experience and work: (in field experience, overall experience and age). Gender and education level matters but to a relatively smaller extent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82771e68",
   "metadata": {},
   "source": [
    "## 4.2 Linear Regression Output\n",
    "- Use linear regression from statsmodel to output regression table, and then write it as a TeX or .txt file using stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4d358fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b286c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processed data\n",
    "X_train_processed = salary_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_processed = salary_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5e670be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the OLS model object\n",
    "X_train_processed = sm.add_constant(X_train_processed) # sm does not automatically add constant to predictors\n",
    "feat_names = list(X_train_processed.columns.values)\n",
    " \n",
    "regr = sm.OLS(y_train,\n",
    "              X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "932c44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          annual_salary   R-squared:                       0.402\n",
      "Model:                            OLS   Adj. R-squared:                  0.401\n",
      "Method:                 Least Squares   F-statistic:                     249.8\n",
      "Date:                Mon, 04 Jul 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:19:25   Log-Likelihood:                -6340.9\n",
      "No. Observations:               16734   AIC:                         1.277e+04\n",
      "Df Residuals:                   16688   BIC:                         1.313e+04\n",
      "Df Model:                          45                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                            10.9001      0.053    205.682      0.000      10.796      11.004\n",
      "age_category                                     -0.0274      0.005     -5.572      0.000      -0.037      -0.018\n",
      "overall_experience                                0.0308      0.004      8.221      0.000       0.023       0.038\n",
      "in_field_experience                               0.0959      0.003     32.249      0.000       0.090       0.102\n",
      "industry_Computing or Tech                        0.6135      0.017     35.739      0.000       0.580       0.647\n",
      "industry_Government and Public Administration     0.2336      0.019     12.424      0.000       0.197       0.270\n",
      "industry_Other                                    0.2315      0.016     14.267      0.000       0.200       0.263\n",
      "industry_Education (Higher Education)             0.0244      0.018      1.373      0.170      -0.010       0.059\n",
      "industry_Law                                      0.2462      0.022     11.086      0.000       0.203       0.290\n",
      "industry_Accounting, Banking & Finance            0.3525      0.019     18.726      0.000       0.316       0.389\n",
      "industry_Nonprofits                               0.1003      0.018      5.648      0.000       0.065       0.135\n",
      "industry_Marketing, Advertising & PR              0.3571      0.021     17.256      0.000       0.317       0.398\n",
      "industry_Health care                              0.3005      0.019     16.134      0.000       0.264       0.337\n",
      "industry_Engineering or Manufacturing             0.4658      0.019     24.569      0.000       0.429       0.503\n",
      "state_Washington                                  0.0861      0.028      3.061      0.002       0.031       0.141\n",
      "state_Other                                      -0.0004      0.021     -0.017      0.986      -0.042       0.041\n",
      "state_Massachusetts                               0.1578      0.026      6.112      0.000       0.107       0.208\n",
      "state_California                                  0.2292      0.023      9.793      0.000       0.183       0.275\n",
      "state_Minnesota                                   0.0495      0.030      1.640      0.101      -0.010       0.109\n",
      "state_Texas                                       0.0887      0.024      3.718      0.000       0.042       0.135\n",
      "state_District of Columbia                        0.2730      0.027     10.251      0.000       0.221       0.325\n",
      "state_New York                                    0.1207      0.025      4.821      0.000       0.072       0.170\n",
      "state_Virginia                                    0.1289      0.026      5.028      0.000       0.079       0.179\n",
      "state_Pennsylvania                                0.0372      0.025      1.509      0.131      -0.011       0.086\n",
      "city_Other                                       -0.1631      0.023     -7.137      0.000      -0.208      -0.118\n",
      "city_Los Angeles                                 -0.1415      0.032     -4.489      0.000      -0.203      -0.080\n",
      "city_Boston                                      -0.0722      0.031     -2.334      0.020      -0.133      -0.012\n",
      "city_Seattle                                     -0.0091      0.033     -0.271      0.786      -0.075       0.057\n",
      "city_San Francisco                                0.0448      0.032      1.415      0.157      -0.017       0.107\n",
      "city_New York                                     0.0136      0.024      0.580      0.562      -0.032       0.060\n",
      "city_Washington                                  -0.1055      0.035     -2.996      0.003      -0.175      -0.036\n",
      "city_Minneapolis                                 -0.0986      0.038     -2.586      0.010      -0.173      -0.024\n",
      "city_Portland                                    -0.0581      0.030     -1.909      0.056      -0.118       0.002\n",
      "city_Chicago                                     -0.0092      0.034     -0.271      0.787      -0.076       0.057\n",
      "gender_Other                                     -0.1629      0.015    -10.669      0.000      -0.193      -0.133\n",
      "gender_Woman                                     -0.0996      0.008    -12.640      0.000      -0.115      -0.084\n",
      "race_White                                       -0.0447      0.017     -2.568      0.010      -0.079      -0.011\n",
      "race_Hispanic, Latino, or Spanish origin         -0.0567      0.026     -2.220      0.026      -0.107      -0.007\n",
      "race_Other                                       -0.0233      0.020     -1.173      0.241      -0.062       0.016\n",
      "race_Asian or Asian American                      0.0697      0.022      3.224      0.001       0.027       0.112\n",
      "education_High School                            -0.3400      0.041     -8.305      0.000      -0.420      -0.260\n",
      "education_Master's degree                         0.0306      0.035      0.865      0.387      -0.039       0.100\n",
      "education_PhD                                     0.2647      0.037      7.114      0.000       0.192       0.338\n",
      "education_College degree                         -0.0880      0.035     -2.497      0.013      -0.157      -0.019\n",
      "education_Some college                           -0.2797      0.037     -7.650      0.000      -0.351      -0.208\n",
      "education_Professional degree (MD, JD, etc.)      0.2953      0.038      7.762      0.000       0.221       0.370\n",
      "==============================================================================\n",
      "Omnibus:                     1658.488   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4854.949\n",
      "Skew:                          -0.536   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.411   Cond. No.                         199.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "res = regr.fit()\n",
    "print(res.summary(xname=feat_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f326c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Stargazer to render regression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "178e845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res must be a sm.ols fitted model with pd.Series (DV) and pd.Dataframe (IV) inputs\n",
    "stargazer = Stargazer([res])\n",
    "\n",
    "# Customize the regression table\n",
    "stargazer.title('Salary survey analysis') # custom title\n",
    "stargazer.show_confidence_intervals(True) # show 95% CI\n",
    "stargazer.rename_covariates({'city_Boston': 'city:Boston'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1132e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Salary survey analysis<br><table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:annual_salary</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">age_category</td><td>-0.027<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.037 , -0.018)</td></tr><tr><td style=\"text-align:left\">city:Boston</td><td>-0.072<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.133 , -0.012)</td></tr><tr><td style=\"text-align:left\">city_Chicago</td><td>-0.009<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.076 , 0.057)</td></tr><tr><td style=\"text-align:left\">city_Los Angeles</td><td>-0.141<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.203 , -0.080)</td></tr><tr><td style=\"text-align:left\">city_Minneapolis</td><td>-0.099<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.173 , -0.024)</td></tr><tr><td style=\"text-align:left\">city_New York</td><td>0.014<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.032 , 0.060)</td></tr><tr><td style=\"text-align:left\">city_Other</td><td>-0.163<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.208 , -0.118)</td></tr><tr><td style=\"text-align:left\">city_Portland</td><td>-0.058<sup>*</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.118 , 0.002)</td></tr><tr><td style=\"text-align:left\">city_San Francisco</td><td>0.045<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.017 , 0.107)</td></tr><tr><td style=\"text-align:left\">city_Seattle</td><td>-0.009<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.075 , 0.057)</td></tr><tr><td style=\"text-align:left\">city_Washington</td><td>-0.106<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.175 , -0.036)</td></tr><tr><td style=\"text-align:left\">const</td><td>10.900<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(10.796 , 11.004)</td></tr><tr><td style=\"text-align:left\">education_College degree</td><td>-0.088<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.157 , -0.019)</td></tr><tr><td style=\"text-align:left\">education_High School</td><td>-0.340<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.420 , -0.260)</td></tr><tr><td style=\"text-align:left\">education_Master's degree</td><td>0.031<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.039 , 0.100)</td></tr><tr><td style=\"text-align:left\">education_PhD</td><td>0.265<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.192 , 0.338)</td></tr><tr><td style=\"text-align:left\">education_Professional degree (MD, JD, etc.)</td><td>0.295<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.221 , 0.370)</td></tr><tr><td style=\"text-align:left\">education_Some college</td><td>-0.280<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.351 , -0.208)</td></tr><tr><td style=\"text-align:left\">gender_Other</td><td>-0.163<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.193 , -0.133)</td></tr><tr><td style=\"text-align:left\">gender_Woman</td><td>-0.100<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.115 , -0.084)</td></tr><tr><td style=\"text-align:left\">in_field_experience</td><td>0.096<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.090 , 0.102)</td></tr><tr><td style=\"text-align:left\">industry_Accounting, Banking & Finance</td><td>0.353<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.316 , 0.389)</td></tr><tr><td style=\"text-align:left\">industry_Computing or Tech</td><td>0.613<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.580 , 0.647)</td></tr><tr><td style=\"text-align:left\">industry_Education (Higher Education)</td><td>0.024<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.010 , 0.059)</td></tr><tr><td style=\"text-align:left\">industry_Engineering or Manufacturing</td><td>0.466<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.429 , 0.503)</td></tr><tr><td style=\"text-align:left\">industry_Government and Public Administration</td><td>0.234<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.197 , 0.270)</td></tr><tr><td style=\"text-align:left\">industry_Health care</td><td>0.301<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.264 , 0.337)</td></tr><tr><td style=\"text-align:left\">industry_Law</td><td>0.246<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.203 , 0.290)</td></tr><tr><td style=\"text-align:left\">industry_Marketing, Advertising & PR</td><td>0.357<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.317 , 0.398)</td></tr><tr><td style=\"text-align:left\">industry_Nonprofits</td><td>0.100<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.065 , 0.135)</td></tr><tr><td style=\"text-align:left\">industry_Other</td><td>0.232<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.200 , 0.263)</td></tr><tr><td style=\"text-align:left\">overall_experience</td><td>0.031<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.023 , 0.038)</td></tr><tr><td style=\"text-align:left\">race_Asian or Asian American</td><td>0.070<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.027 , 0.112)</td></tr><tr><td style=\"text-align:left\">race_Hispanic, Latino, or Spanish origin</td><td>-0.057<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.107 , -0.007)</td></tr><tr><td style=\"text-align:left\">race_Other</td><td>-0.023<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.062 , 0.016)</td></tr><tr><td style=\"text-align:left\">race_White</td><td>-0.045<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.079 , -0.011)</td></tr><tr><td style=\"text-align:left\">state_California</td><td>0.229<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.183 , 0.275)</td></tr><tr><td style=\"text-align:left\">state_District of Columbia</td><td>0.273<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.221 , 0.325)</td></tr><tr><td style=\"text-align:left\">state_Massachusetts</td><td>0.158<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.107 , 0.208)</td></tr><tr><td style=\"text-align:left\">state_Minnesota</td><td>0.050<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.010 , 0.109)</td></tr><tr><td style=\"text-align:left\">state_New York</td><td>0.121<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.072 , 0.170)</td></tr><tr><td style=\"text-align:left\">state_Other</td><td>-0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.042 , 0.041)</td></tr><tr><td style=\"text-align:left\">state_Pennsylvania</td><td>0.037<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.011 , 0.086)</td></tr><tr><td style=\"text-align:left\">state_Texas</td><td>0.089<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.042 , 0.135)</td></tr><tr><td style=\"text-align:left\">state_Virginia</td><td>0.129<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.079 , 0.179)</td></tr><tr><td style=\"text-align:left\">state_Washington</td><td>0.086<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.031 , 0.141)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>16,734</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.402</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.401</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.354 (df=16688)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>249.808<sup>***</sup> (df=45; 16688)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x12fb7b940>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stargazer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9f282",
   "metadata": {},
   "source": [
    "**Render html code using stargazer and output .html file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8e418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can render latex code, or html code and write it onto a file\n",
    "html_code=stargazer.render_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d89c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = open(Path(\"outputs\",\"linear_regression_results.html\"), \"w\")\n",
    "_n = html_file.write(html_code)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d00616",
   "metadata": {},
   "source": [
    "**Render LaTeX code using stargazer and output .tex file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cee4161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_code=stargazer.render_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "457f0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_file = open(Path(\"outputs\",\"linear_regression_results.tex\"), \"w\")\n",
    "_n = tex_file.write(tex_code)\n",
    "tex_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
