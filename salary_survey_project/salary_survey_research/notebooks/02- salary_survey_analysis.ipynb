{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680b9018",
   "metadata": {},
   "source": [
    "# Salary analysis\n",
    "- We will perform the following:\n",
    "    - Clean and reformat the data\n",
    "    - Split data into train/test split\n",
    "    - Create data pipeline to process data\n",
    "    - Get performance of baseline model\n",
    "    - Use k-fold CV to estimate the test performance metric (e.g., mean rmse across all CV folds) of several candidate models\n",
    "    - For the \"best\" model with the highest test metric, perform hyperparameter tuning\n",
    "        - Use RandomizedSearchCV to identify a set of potential optimal values for the hyperparameter. Refine the tuning with GridSearchCV. Get the mean CV score of the best model. Make predictions with the best model using the test set and get the test metric of the test set.\n",
    "    - Use GridSearchCV to tune hyperparameters for multiple pipelines (which has the model as the last transformer in the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54646a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "'''data'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''visualization'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''feature engine'''\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OneHotEncoder)\n",
    "\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "'''sklearn'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''models'''\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "'''performance evaluation'''\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "'''others'''\n",
    "from random import sample # randomly sample elements from a list\n",
    "import joblib # persist models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f610fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory to be one level above /notebook during the INIT RUN \n",
    "try: INIT_RUN\n",
    "except NameError:\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    INIT_RUN=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e577f1",
   "metadata": {},
   "source": [
    "## Project Parameters\n",
    "- Gather all project parameters here, they will be set inside a yaml config file in a future iteration of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac1ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root and data directory of project\n",
    "ROOT_DIR = os.getcwd()\n",
    "RAW_DATA_DIR = Path(ROOT_DIR,\"data\",\"raw\")\n",
    "PROCESSED_DATA_DIR = Path(ROOT_DIR,\"data\",\"processed\")\n",
    "\n",
    "# Selected features\n",
    "FEATURES = [\"age_category\",\"industry\",\"state\",\"city\",\n",
    "            \"overall_experience\",\"in_field_experience\",\n",
    "            \"education\",\"gender\",\"race\"]\n",
    "\n",
    "# Modelling parameters\n",
    "RANDOM = 10\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Custom lower bound for outlier removal\n",
    "OUTLIER_LWR_BOUND = 5000\n",
    "\n",
    "\n",
    "# Data pipeline\n",
    "# Variables that I retain the X most frequent level and lump the rest as \"Other\"\n",
    "CAT_VARS_10_MOST_FREQ = [\"state\",\"city\",\"industry\"]\n",
    "CAT_VARS_2_MOST_FREQ = [\"gender\"]\n",
    "CAT_VARS_4_MOST_FREQ = [\"race\"]\n",
    "\n",
    "# impute missing values with \"missing\"\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = [\"industry\",\"state\",\"city\",\"education\",\"gender\",\"race\"]\n",
    "\n",
    "# variable mappings (string to integer encoding)\n",
    "EXPERIENCE_VARS = [\"overall_experience\",\"in_field_experience\"]\n",
    "AGE_VARS = [\"age_category\"]\n",
    "\n",
    "# one-hot encoding\n",
    "NOMINAL_VARIABLES = [\"industry\",\"state\",\"city\",\"gender\",\"race\",\"education\"]\n",
    "\n",
    "# Fit Gradient boosted tree and random forest models\n",
    "EXECUTE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e6c15",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "- Will be placed in a separate module later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051811c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_get_levels(df,col):\n",
    "    ordered_levels = (df[col]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={'index':'levels'})\n",
    "     # extract the first one (or more) digits\n",
    "    .assign(num_levels=lambda x: x.levels.str.extract(r'(\\d+)').astype(int))\n",
    "    .sort_values(\"num_levels\")\n",
    "    .levels\n",
    "    .tolist())\n",
    "    \n",
    "    # create categorical type\n",
    "    categorical_type =  pd.api.types.CategoricalDtype(\n",
    "    categories=ordered_levels,\n",
    "    ordered=True)\n",
    "    \n",
    "    # convert col to ordered categorical type\n",
    "    df[col] = df[col].astype(categorical_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name, lwr_bound =None, upr_bound=None):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    \n",
    "    if lwr_bound is None:\n",
    "        lwr_bound  = q1-1.5*iqr\n",
    "    \n",
    "    if upr_bound is None:\n",
    "        upr_bound = q3+1.5*iqr\n",
    "    \n",
    "    df_out = df_in.loc[(df_in[col_name] > lwr_bound) & (df_in[col_name] < upr_bound)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d957fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to test\n",
    "def get_models():\n",
    "    # init list of models with associated names\n",
    "    models,names = list(), list()\n",
    "    \n",
    "    # linear regression\n",
    "    models.append(LinearRegression())\n",
    "    names.append(\"linear_regression\")\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    models.append(RandomForestRegressor())\n",
    "    names.append(\"random_forest\")\n",
    "    \n",
    "    # Gradient Boosted Trees\n",
    "    models.append(GradientBoostingRegressor())\n",
    "    names.append(\"gradient_boosting\")\n",
    "    \n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43a4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a model with k-fold cross validation\n",
    "def evaluate_model(X,y,model):\n",
    "    scores = cross_val_score(\n",
    "        estimator = model,\n",
    "        X = X,\n",
    "        y = y,\n",
    "        cv = 10,\n",
    "        scoring = \"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e52bc0",
   "metadata": {},
   "source": [
    "### Custom transformer\n",
    "- Map string levels to numeric levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6c5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Categorical variables encoding (the encoding of categorical variables that already have ordered\n",
    "# levels from strings to numeric)\n",
    "\n",
    "class Mapper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Constructor\n",
    "\n",
    "    Args:\n",
    "        variables (List[str]): a list of variables to be recoded (specified by user)\n",
    "        mappings (dict): a dictionary of mappings from old to new encoding\n",
    "\n",
    "    Returns:\n",
    "        void\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, variables, mappings):\n",
    "\n",
    "        # Error handling: check to ensure variables is a list\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "\n",
    "        # Error handling: check to ensure variables is a dict\n",
    "        if not isinstance(mappings, dict):\n",
    "            raise ValueError('mapping should be a dictionary')\n",
    "\n",
    "        # set attributes at instantiation of class\n",
    "        self.variables = variables\n",
    "        self.mappings = mappings\n",
    "\n",
    "    def fit(self, X,\n",
    "            y=None):  # need to have y as argument to make class compatible with sklearn pipeline\n",
    "        \"\"\" Fit\n",
    "\n",
    "        Args:\n",
    "            X (DataFrame): a input dataframe of features to train the transformer\n",
    "            y (DataFrame): a input Series of response variable to train the transformer (optional)\n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # We don't need to learn any parameters for this transformer. Nonetheless, we still need\n",
    "        # to include a fit method so that the Transformer class would be compatible to sklearn\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Transform\n",
    "\n",
    "        Args:\n",
    "            X (DataFrame): a input dataframe of features to be transformed\n",
    "\n",
    "        Returns:\n",
    "            X (DataFrame): the transformed Dataframe of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Make a copy of the input Dataframe of features to be transformed\n",
    "        # so we won't overwrite the original Dataframe that was passed as argument\n",
    "        X = X.copy()\n",
    "\n",
    "        # Perform recoding of the levels of var\n",
    "        for var in self.variables:\n",
    "            X[var] = X[var].map(self.mappings)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd4cc9",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac6f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv(Path(RAW_DATA_DIR,\"survey.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d8cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only focus on respondents (>83% of them) that are paid in USD\n",
    "survey_usd = survey.loc[survey[\"currency\"]=='USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776fbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables and numeric variables\n",
    "cat_vars = [var for var in survey_usd.columns if survey_usd[var].dtype=='O']\n",
    "num_vars = [var for var in survey_usd.columns if survey_usd[var].dtype!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5873e",
   "metadata": {},
   "source": [
    "## Clean and reformat data\n",
    "- Convert timestamp to datetime\n",
    "- Reformat state, overall_experience, in_field_experience, and age, and convert these variables to ordered categorical variables\n",
    "- Rename variables\n",
    "- Remove outliers (5000,75th percentile+3*IQR)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154630e5",
   "metadata": {},
   "source": [
    "**These are steps that do not have to be included in a data pipeline (does not cause data leakage). Let's implement these steps here.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92d460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "survey_usd.loc[:,'timestamp'] = survey_usd.loc[:,'timestamp'].astype('datetime64[ns]')\n",
    "\n",
    "# state\n",
    "# Only take the first state in the response and ignore the rest\n",
    "survey_usd[\"state\"]=survey_usd[\"state\"].str.split(',').str[0]\n",
    "\n",
    "# overall_years_of_professional_experience\n",
    "survey_usd['overall_years_of_professional_experience'] = (survey_usd['overall_years_of_professional_experience']\n",
    "                                                      .str\n",
    "                                                      .replace(' - ','-'))\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"overall_years_of_professional_experience\")\n",
    "\n",
    "# years_of_experience_in_field\n",
    "survey_usd['years_of_experience_in_field'] = (survey_usd['years_of_experience_in_field']\n",
    "                                                      .str\n",
    "                                                      .replace(' - ','-'))\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"years_of_experience_in_field\")\n",
    "\n",
    "\n",
    "# age\n",
    "\n",
    "# Need to rename the \"under 18\" level to \"17 or under\" so it can be parsed by the parse_num_get_levels() function\n",
    "survey_usd[\"how_old_are_you\"]=survey_usd[\"how_old_are_you\"].replace(to_replace = \"under 18\",\n",
    "                                                                   value=\"17 or under\")\n",
    "\n",
    "parse_num_get_levels(survey_usd,\n",
    "                     \"how_old_are_you\")\n",
    "\n",
    "# rename variables\n",
    "survey_usd=survey_usd.rename(columns={\"how_old_are_you\": \"age_category\",\n",
    "                                      \"overall_years_of_professional_experience\":\"overall_experience\",\n",
    "                                      \"years_of_experience_in_field\": \"in_field_experience\",\n",
    "                                      \"highest_level_of_education_completed\":\"education\"},                             \n",
    "                             errors=\"raise\")\n",
    "\n",
    "# Remove outliers\n",
    "survey_usd = remove_outlier(df_in = survey_usd, \n",
    "                            col_name = \"annual_salary\",\n",
    "                            lwr_bound = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e88fe",
   "metadata": {},
   "source": [
    "**Get a dictionary that maps the ordered levels of overall_experience (note: in_field_experience has the same levels) to an integer ordered from (0,number of levels -1). This will be used in the recoding transformer that will be used on overall_experience and in_field_experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709ddb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict(enumerate(survey_usd['overall_experience'].cat.categories))\n",
    "\n",
    "# Set key to value and value to key as per the requirements of \n",
    "# .map() method used in Mapper transformer in preprocessing.py\n",
    "DICT_EXPERIENCE_ORDERED_LEVELS = {v: k for k, v in temp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e17930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 year or less': 0,\n",
       " '2-4 years': 1,\n",
       " '5-7 years': 2,\n",
       " '8-10 years': 3,\n",
       " '11-20 years': 4,\n",
       " '21-30 years': 5,\n",
       " '31-40 years': 6,\n",
       " '41 years or more': 7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_EXPERIENCE_ORDERED_LEVELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4daeb",
   "metadata": {},
   "source": [
    "**Get a dictionary that maps the ordered levels of age_category to an integer ordered from (0,number of levels -1). This will be used in the Mapper function for age.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa67fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict(enumerate(survey_usd['age_category'].cat.categories))\n",
    "DICT_AGE_ORDERED_LEVELS= {v: k for k, v in temp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e338e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'17 or under': 0,\n",
       " '18-24': 1,\n",
       " '25-34': 2,\n",
       " '35-44': 3,\n",
       " '45-54': 4,\n",
       " '55-64': 5,\n",
       " '65 or over': 6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_AGE_ORDERED_LEVELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a4f57",
   "metadata": {},
   "source": [
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a71528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16734, 17), (4184, 17))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    survey_usd.drop([\"annual_salary\"], axis=\"columns\"), # features\n",
    "    survey_usd[\"annual_salary\"], # target\n",
    "    test_size = TEST_SIZE,\n",
    "    random_state = RANDOM\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1ff31",
   "metadata": {},
   "source": [
    "**Apply log transformation on DV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19cbcf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75581a9",
   "metadata": {},
   "source": [
    "**Get data subset of selected features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bcfe16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7cc3e",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8a9ba",
   "metadata": {},
   "source": [
    "- We need to impute missing values for 6 features with a new level called \"missing\".\n",
    "- Lump the rare levels of the following categorical variables to \"Other\":\n",
    "    - state\n",
    "    - city\n",
    "    - race \n",
    "    - gender \n",
    "    - industry \n",
    "- Map string encoding to integer encoding for the following ordinal variables:\n",
    "    - overall_experience\n",
    "    - in_field_experience\n",
    "    - age_category\n",
    "- One hot encode nominal features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cf886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_pipeline = Pipeline([\n",
    "    \n",
    "    \n",
    "    # === Imputation ===\n",
    "    # Imputing missing values in categorical variables (with a new \"missing\" level)\n",
    "    # CategoricalImputer from feature_engine\n",
    "    ('missing_imputation', CategoricalImputer(imputation_method='missing',\n",
    "                                             variables=CATEGORICAL_VARS_WITH_NA_MISSING)),\n",
    "    \n",
    "    \n",
    "    # === Recoding categorical variables ===\n",
    "    (\"rare_label_encoder_10\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 10,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_10_MOST_FREQ)),\n",
    "    \n",
    "    (\"rare_label_encoder_2\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 2,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_2_MOST_FREQ)),\n",
    "    \n",
    "    (\"rare_label_encoder_4\", RareLabelEncoder(tol=0.01,\n",
    "                                            max_n_categories = 4,\n",
    "                                            n_categories=1,\n",
    "                                            replace_with = \"Other\",\n",
    "                                            variables = CAT_VARS_4_MOST_FREQ)),\n",
    "    \n",
    "    # === Recoding categorical variables with ordered level ===\n",
    "    \n",
    "    # Recode categorical variables with ordered level: map from string encoding to numeric encoding\n",
    "    # Use custom class from 'preprocessing.py' Mappers\n",
    "    ('mapper_exp',Mapper(\n",
    "        variables=EXPERIENCE_VARS, mappings=DICT_EXPERIENCE_ORDERED_LEVELS)),\n",
    "\n",
    "    ('mapper_age', Mapper(\n",
    "        variables=AGE_VARS, mappings=DICT_AGE_ORDERED_LEVELS)),\n",
    "    \n",
    "     # === One-hot enccode nominal variables ===\n",
    "    ('one_hot_encoder', OneHotEncoder(drop_last=True, # avoid dummy variable trap\n",
    "                                      variables = NOMINAL_VARIABLES))\n",
    "    \n",
    "\n",
    "])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a18c20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;missing_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;,\n",
       "                                               &#x27;education&#x27;, &#x27;gender&#x27;,\n",
       "                                               &#x27;race&#x27;])),\n",
       "                (&#x27;rare_label_encoder_10&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with=&#x27;Other&#x27;, tol=0.01,\n",
       "                                  variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])),\n",
       "                (&#x27;rare_label_encoder_2&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                                  &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "                        variables=[&#x27;overall_experience&#x27;,\n",
       "                                   &#x27;in_field_experience&#x27;])),\n",
       "                (&#x27;mapper_age&#x27;,\n",
       "                 Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2,\n",
       "                                  &#x27;35-44&#x27;: 3, &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5,\n",
       "                                  &#x27;65 or over&#x27;: 6},\n",
       "                        variables=[&#x27;age_category&#x27;])),\n",
       "                (&#x27;one_hot_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;,\n",
       "                                          &#x27;race&#x27;, &#x27;education&#x27;]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;missing_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;,\n",
       "                                               &#x27;education&#x27;, &#x27;gender&#x27;,\n",
       "                                               &#x27;race&#x27;])),\n",
       "                (&#x27;rare_label_encoder_10&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with=&#x27;Other&#x27;, tol=0.01,\n",
       "                                  variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])),\n",
       "                (&#x27;rare_label_encoder_2&#x27;,\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                                  &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "                        variables=[&#x27;overall_experience&#x27;,\n",
       "                                   &#x27;in_field_experience&#x27;])),\n",
       "                (&#x27;mapper_age&#x27;,\n",
       "                 Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2,\n",
       "                                  &#x27;35-44&#x27;: 3, &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5,\n",
       "                                  &#x27;65 or over&#x27;: 6},\n",
       "                        variables=[&#x27;age_category&#x27;])),\n",
       "                (&#x27;one_hot_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;,\n",
       "                                          &#x27;race&#x27;, &#x27;education&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;education&#x27;,\n",
       "                              &#x27;gender&#x27;, &#x27;race&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=10, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;state&#x27;, &#x27;city&#x27;, &#x27;industry&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=2, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;gender&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(max_n_categories=4, n_categories=1, replace_with=&#x27;Other&#x27;,\n",
       "                 tol=0.01, variables=[&#x27;race&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Mapper</label><div class=\"sk-toggleable__content\"><pre>Mapper(mappings={&#x27;1 year or less&#x27;: 0, &#x27;11-20 years&#x27;: 4, &#x27;2-4 years&#x27;: 1,\n",
       "                 &#x27;21-30 years&#x27;: 5, &#x27;31-40 years&#x27;: 6, &#x27;41 years or more&#x27;: 7,\n",
       "                 &#x27;5-7 years&#x27;: 2, &#x27;8-10 years&#x27;: 3},\n",
       "       variables=[&#x27;overall_experience&#x27;, &#x27;in_field_experience&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Mapper</label><div class=\"sk-toggleable__content\"><pre>Mapper(mappings={&#x27;17 or under&#x27;: 0, &#x27;18-24&#x27;: 1, &#x27;25-34&#x27;: 2, &#x27;35-44&#x27;: 3,\n",
       "                 &#x27;45-54&#x27;: 4, &#x27;55-64&#x27;: 5, &#x27;65 or over&#x27;: 6},\n",
       "       variables=[&#x27;age_category&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True,\n",
       "              variables=[&#x27;industry&#x27;, &#x27;state&#x27;, &#x27;city&#x27;, &#x27;gender&#x27;, &#x27;race&#x27;,\n",
       "                         &#x27;education&#x27;])</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('missing_imputation',\n",
       "                 CategoricalImputer(variables=['industry', 'state', 'city',\n",
       "                                               'education', 'gender',\n",
       "                                               'race'])),\n",
       "                ('rare_label_encoder_10',\n",
       "                 RareLabelEncoder(max_n_categories=10, n_categories=1,\n",
       "                                  replace_with='Other', tol=0.01,\n",
       "                                  variables=['state', 'city', 'industry'])),\n",
       "                ('rare_label_encoder_2',\n",
       "                 RareLabelEncoder(max_n_categories=2, n_categories=1,\n",
       "                                  rep...\n",
       "                                  '31-40 years': 6, '41 years or more': 7,\n",
       "                                  '5-7 years': 2, '8-10 years': 3},\n",
       "                        variables=['overall_experience',\n",
       "                                   'in_field_experience'])),\n",
       "                ('mapper_age',\n",
       "                 Mapper(mappings={'17 or under': 0, '18-24': 1, '25-34': 2,\n",
       "                                  '35-44': 3, '45-54': 4, '55-64': 5,\n",
       "                                  '65 or over': 6},\n",
       "                        variables=['age_category'])),\n",
       "                ('one_hot_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['industry', 'state', 'city', 'gender',\n",
       "                                          'race', 'education']))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline to train data\n",
    "salary_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe176f",
   "metadata": {},
   "source": [
    "## Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8478b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and X_test with the fitted pipeline\n",
    "X_train = salary_pipeline.transform(X_train)\n",
    "X_test = salary_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "298bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the column names of the processed X_train data\n",
    "feature_columns = X_train.columns.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86206392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed X_train, X_test, y_train and y_test\n",
    "X_train.to_csv(Path(PROCESSED_DATA_DIR,\"X_train.csv\"))\n",
    "X_test.to_csv(Path(PROCESSED_DATA_DIR,\"X_test.csv\"))\n",
    "\n",
    "y_train.to_csv(Path(PROCESSED_DATA_DIR,\"y_train.csv\"))\n",
    "y_test.to_csv(Path(PROCESSED_DATA_DIR,\"y_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28517a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9015662",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02331c36",
   "metadata": {},
   "source": [
    "## 00- Baseline model\n",
    "- A naive guess of what the employee salary are. We make the same predictions for each employee-- the median salary across all employees in the train (and test) data.\n",
    "- Having a baseline prediction will allow us to see how much of an improvement I can get if I use an statistical learning approach. If the improvement is very small, then perhaps statistical learning is not a suitable approach for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eae2f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "       ...    \n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "0    11.240867\n",
       "Length: 4184, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_pred = np.median(np.log(survey_usd[\"annual_salary\"]))\n",
    "# make this into a pd.Series with the same length as y_test\n",
    "y_pred_baseline = pd.Series(baseline_pred).repeat(y_test.shape[0])\n",
    "y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae053bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of the baseline model is 0.47\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rmse of the baseline model is {round(mean_squared_error(y_test,y_pred_baseline, squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454ccd5",
   "metadata": {},
   "source": [
    "**Alternatively, use sklearn.DummyRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a2c05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor(strategy=&#x27;median&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor(strategy='median')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init the dummy regressor\n",
    "dummy_regr = DummyRegressor(strategy=\"median\")\n",
    "# Train the model\n",
    "dummy_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51e82c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of the baseline model is 0.47.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and get baseline performance\n",
    "y_pred_baseline=dummy_regr.predict(X_test)\n",
    "print(f\"The rmse of the baseline model is {round(mean_squared_error(y_test,y_pred_baseline, squared=False),2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a5d33",
   "metadata": {},
   "source": [
    "## 1. Train the following models: linear regression, random forest, gradient boosting and compare their estimated test metric (k-fold cv scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb475b",
   "metadata": {},
   "source": [
    "**Init models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82732ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, names = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9c056ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([LinearRegression(), RandomForestRegressor(), GradientBoostingRegressor()],\n",
       " ['linear_regression', 'random_forest', 'gradient_boosting'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a88958",
   "metadata": {},
   "source": [
    "**Evaluate models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48d1d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear_regression', 0.35, 0.01)\n",
      "('random_forest', 0.38, 0.01)\n",
      "('gradient_boosting', 0.36, 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model (get estimated test metric) and store the results in a list \"l_mean_cv_scores\"\n",
    "l_cv_scores = list()\n",
    "for model, name in list(zip(models, names)):\n",
    "    \n",
    "    # Compute cv scores of each model\n",
    "    cv_scores = evaluate_model(X_train, y_train, model)\n",
    "    \n",
    "    # Update the list of model results, each row represent the cv scores of a model\n",
    "    l_cv_scores.append(cv_scores)\n",
    "\n",
    "    # Summary of model performance\n",
    "    print((name, round(-cv_scores.mean(),2), round(np.std(cv_scores),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5050ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative rmse')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.boxplot(l_cv_scores, labels=names, showmeans=True)\n",
    "plt.ylabel(\"negative rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef9f23",
   "metadata": {},
   "source": [
    "- Linear regression model has the best performance-- it has the least rmse (average percent deviation of data from geometric mean of annual salary across all train observations)\n",
    "- We can tune random forest and gradient boosting to see if the tuned models can outperform linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea0b49",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter tuning for random forest and gradient boosted trees\n",
    "- Here, I will tune both the random forest and gradient boosted tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210dc2c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9852b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfff63",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV for Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63b48572",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "   \"n_estimators\": [10, 100, 1000],\n",
    "    \"max_features\": ['sqrt','log2'],\n",
    "    \"max_depth\": [None,1,3,10,40,50],\n",
    "    \"min_samples_split\": [2,5,10,50,100],\n",
    "    \"min_samples_leaf\": [2,5,10,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a73e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search of the parameters, using a 10 fold CV to estimate the test metric for each setting.\n",
    "rand_grid_search = RandomizedSearchCV(estimator = reg,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 20,  # randomly select 20 different settings to try\n",
    "                                cv = 10,       # use 10-fold CV for each setting to estimate its test metric\n",
    "                                scoring=\"neg_root_mean_squared_error\",\n",
    "                                verbose = 1, #2   # show the process\n",
    "                                n_jobs =-1,  # use all processors\n",
    "                                random_state = RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56625df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 1, 3, 10, 40, 50],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 5, 10, 50, 100],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 1, 3, 10, 40, 50],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 5, 10, 50, 100],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 1, 3, 10, 40, 50],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [2, 5, 10, 50, 100],\n",
       "                                        'min_samples_split': [2, 5, 10, 50,\n",
       "                                                              100],\n",
       "                                        'n_estimators': [10, 100, 1000]},\n",
       "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4cc73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean CV score (rmse) of the best estimator is: 0.357108796399515\n",
      "The best alpha for the rf model from RandomGridSearch is {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean CV score (rmse) of the best estimator is: {-rand_grid_search.best_score_}\")\n",
    "print(f\"The best alpha for the rf model from RandomGridSearch is {rand_grid_search.best_params_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ad231",
   "metadata": {},
   "source": [
    "**GridSearchCV for Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1845705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=1000,\n",
    "                           max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42360204",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [35,40,45],\n",
    "    \"min_samples_split\": [4,5,6],\n",
    "    \"min_samples_leaf\": [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6be085c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           scoring=\"neg_root_mean_squared_error\",\n",
    "                           verbose =1, # show the process\n",
    "                           n_jobs = -1)  # n_jobs = -1 means use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdd481cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "The optimal parameter from GridSearchCV is: {'max_depth': 35, 'min_samples_leaf': 3, 'min_samples_split': 6}\n",
      "\n",
      "The mean CV score (rmse) of the model with the best parameter is: 0.35676027115097075\n",
      "The test rmse of the tuned model estimated using the test set is: 0.36\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    \n",
    "    # The optimal parameter\n",
    "    print(f\"The optimal parameter from GridSearchCV is: {grid_search.best_params_}\")\n",
    "\n",
    "    # The score of the model with the optimal parameter\n",
    "    print(f\"\\nThe mean CV score (rmse) of the model with the best parameter is: {-grid_search.best_score_}\")\n",
    "    \n",
    "    # Get the model that uses the \"best\" hp, trained from the full train set\n",
    "    best_reg = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions using X_test\n",
    "    y_pred = best_reg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance of the model (rmse) with the test set\n",
    "    print(f\"The test rmse of the tuned model estimated using the test set is: {round(mean_squared_error(y_test,y_pred,squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b937fca",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2ca359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e4cb7",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV for gb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b931e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "   \"n_estimators\": [100, 500, 1000], # number of trees to build\n",
    "   \"learning_rate\": [0.01,0.05,0.1], # learning rate\n",
    "   \"max_depth\":[4,6,8,10], # maximum depth of each tree\n",
    "   \"subsample\":[0.5,0.75,1.0], # prop of train set (observations) to consider for each tree\n",
    "   \"max_features\":[0.4,0.6,0.8,1.0] # prop of features to consider for each split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f350f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search of the parameters, using a 10 fold CV to estimate the test metric for each setting.\n",
    "rand_grid_search = RandomizedSearchCV(estimator = reg,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 20,  # randomly select 20 different settings to try\n",
    "                                cv = 10,       # use 10-fold CV for each setting to estimate its test metric\n",
    "                                scoring=\"neg_root_mean_squared_error\",\n",
    "                                verbose = 1, #2   # show the process\n",
    "                                n_jobs =-1,  # use all processors\n",
    "                                random_state = RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d28a604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                                        &#x27;max_features&#x27;: [0.4, 0.6, 0.8, 1.0],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                                        &#x27;max_features&#x27;: [0.4, 0.6, 0.8, 1.0],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1],\n",
       "                                        'max_depth': [4, 6, 8, 10],\n",
       "                                        'max_features': [0.4, 0.6, 0.8, 1.0],\n",
       "                                        'n_estimators': [100, 500, 1000],\n",
       "                                        'subsample': [0.5, 0.75, 1.0]},\n",
       "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff883006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean CV score (rmse) of the best estimator is: 0.3508543676246644\n",
      "The best alpha for the gb model from RandomGridSearch is {'subsample': 1.0, 'n_estimators': 1000, 'max_features': 0.4, 'max_depth': 4, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean CV score (rmse) of the best estimator is: {-rand_grid_search.best_score_}\")\n",
    "print(f\"The best alpha for the gb model from RandomGridSearch is {rand_grid_search.best_params_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6736ab",
   "metadata": {},
   "source": [
    "**GridSearchCV for Gradient Boosted trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0d96744",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=1000,\n",
    "                                subsample=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ee22a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\":[0.02,0.05,0.08],\n",
    "    \"max_depth\": [3,4,5],\n",
    "    \"max_features\": [0.3,0.4,0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c0b41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           scoring=\"neg_root_mean_squared_error\",\n",
    "                           verbose =1, # show the process\n",
    "                           n_jobs = -1)  # n_jobs = -1 means use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "904cbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "The optimal parameter from GridSearchCV is: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 0.3}\n",
      "\n",
      "The mean CV score (rmse) of the model with the best parameter is: 0.3504984231307054\n",
      "The test rmse of the tuned model estimated using the test set is: 0.35\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    \n",
    "    # The optimal parameter\n",
    "    print(f\"The optimal parameter from GridSearchCV is: {grid_search.best_params_}\")\n",
    "\n",
    "    # The score of the model with the optimal parameter\n",
    "    print(f\"\\nThe mean CV score (rmse) of the model with the best parameter is: {-grid_search.best_score_}\")\n",
    "    \n",
    "    # Get the model that uses the \"best\" hp, trained from the full train set\n",
    "    best_reg = grid_search.best_estimator_\n",
    "    # Make predictions using X_test\n",
    "    y_pred = best_reg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance of the model (rmse) with the test set\n",
    "    print(f\"The test rmse of the tuned model estimated using the test set is: {round(mean_squared_error(y_test,y_pred,squared=False),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81044f",
   "metadata": {},
   "source": [
    "**By tuning hyperparameters, the performance of random forest and gb is close to linear regression model (close to 0.35). However, since linear regression has fast training time and interpretible, we should use linear regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1632ce0",
   "metadata": {},
   "source": [
    "## 3. Tune data pipelines that uses Random Forest and Gradient boosted trees models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a651ab8",
   "metadata": {},
   "source": [
    "- Instead of transforming X_train, X_test with the data pipeline to get \"processed\" data, and then use the processed data to train models, I can directly use data pipelines (with models as the last step) in GridSearchCV\n",
    "- An additional advantage of using pipelines in GridSearchCV is that we can tune parameters in the data processing steps as well (e.g., rare labels labelling-- number of levels to keep, or parameters in tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9110a9",
   "metadata": {},
   "source": [
    "### Test harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c414de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16734, 17), (4184, 17))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    survey_usd.drop([\"annual_salary\"], axis=\"columns\"), # features\n",
    "    survey_usd[\"annual_salary\"], # target\n",
    "    test_size = TEST_SIZE,\n",
    "    random_state = RANDOM\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74178fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99338986",
   "metadata": {},
   "source": [
    "**A list of models to tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "812ea7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=1000,\n",
    "                                            max_features=\"sqrt\"),\n",
    "    \"gradient_boosting\": GradientBoostingRegressor(n_estimators=1000,\n",
    "                                               subsample=1.0)    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ddefa",
   "metadata": {},
   "source": [
    "**Hyperparameters for data processing steps in pipeline (if any) and for each model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3d371b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict of dicts\n",
    "param_grid = {\n",
    "    # == random forest ==\n",
    "    \"random_forest\": {\n",
    "        \"regressor__max_depth\": [35,40,45],\n",
    "        \"regressor__min_samples_split\":[4,5,6],\n",
    "        \"regressor__min_samples_leaf\":[1,2,3]    \n",
    "    },\n",
    "    # == gradient boosting ==\n",
    "    \"gradient_boosting\":{\n",
    "        \"regressor__learning_rate\": [0.02,0.05,0.08],\n",
    "        \"regressor__max_depth\": [3,4,5],\n",
    "        \"regressor__max_features\": [0.3,0.4,0.5]        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10137116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "if EXECUTE:\n",
    "    results=[] # init a list that contains results for each model\n",
    "\n",
    "    for model_name in models.keys():\n",
    "       \n",
    "        # append current model to pipeline as the last step (ex: 'regressor, RandomForestRegressor()')\n",
    "        salary_pipeline.steps.append(['regressor', models[model_name]])\n",
    "    \n",
    "        # Get the params for the current model\n",
    "        params = param_grid[model_name]\n",
    "    \n",
    "        # Init GridSearchCV \n",
    "        grid = GridSearchCV(estimator = salary_pipeline, \n",
    "                            param_grid = params, \n",
    "                            cv = 5, \n",
    "                            scoring=\"neg_root_mean_squared_error\",\n",
    "                            verbose =1, # show the process\n",
    "                            n_jobs = -1)  # n_jobs = -1 means use all processors    \n",
    "    \n",
    "        # Fit GridSearchCV\n",
    "        grid.fit(X_train, y_train)\n",
    "    \n",
    "        # remove last step (model) of the pipeline so it can be reused for the next iter (model)\n",
    "        salary_pipeline=salary_pipeline[:-1]\n",
    "    \n",
    "        # Collect results of GridSearchCV\n",
    "        results.append({\n",
    "            'model_name': model_name,\n",
    "            'grid': grid,\n",
    "            'best_estimator': grid.best_estimator_,\n",
    "            'best_score': grid.best_score_,\n",
    "            'best_params': grid.best_params_\n",
    "        })\n",
    "        \n",
    "        # Persist model\n",
    "        joblib.dump(grid.best_estimator_,Path(ROOT_DIR,\"models\",f\"{model_name}.joblib\"))\n",
    "\n",
    "    # Look at results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = (df_results\n",
    "                  .rename(df_results[\"model_name\"],axis=\"index\"))\n",
    "    df_results[\"best_score\"] = -1*df_results[\"best_score\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "845f6b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>grid</th>\n",
       "      <th>best_estimator</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>(CategoricalImputer(variables=['industry', 'st...</td>\n",
       "      <td>0.357052</td>\n",
       "      <td>{'regressor__max_depth': 35, 'regressor__min_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_boosting</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>(CategoricalImputer(variables=['industry', 'st...</td>\n",
       "      <td>0.351383</td>\n",
       "      <td>{'regressor__learning_rate': 0.05, 'regressor_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model_name  \\\n",
       "random_forest          random_forest   \n",
       "gradient_boosting  gradient_boosting   \n",
       "\n",
       "                                                                grid  \\\n",
       "random_forest      GridSearchCV(cv=5,\\n             estimator=Pip...   \n",
       "gradient_boosting  GridSearchCV(cv=5,\\n             estimator=Pip...   \n",
       "\n",
       "                                                      best_estimator  \\\n",
       "random_forest      (CategoricalImputer(variables=['industry', 'st...   \n",
       "gradient_boosting  (CategoricalImputer(variables=['industry', 'st...   \n",
       "\n",
       "                   best_score  \\\n",
       "random_forest        0.357052   \n",
       "gradient_boosting    0.351383   \n",
       "\n",
       "                                                         best_params  \n",
       "random_forest      {'regressor__max_depth': 35, 'regressor__min_s...  \n",
       "gradient_boosting  {'regressor__learning_rate': 0.05, 'regressor_...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b4ef",
   "metadata": {},
   "source": [
    "**Both the tuned random forest and gradient boosting have a similar rmse to the linear regression model (0.35). The performance (rmse) is not very different across the three model. Due to the simplicity, low training time and computational requirement, and interpretibility of the linear regression model, I will select this model for this problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23bd02",
   "metadata": {},
   "source": [
    "## 4. Feature importance from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "689d70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best random forest model pipeline\n",
    "best_rf_pipeline=joblib.load(Path(ROOT_DIR,\"models\",\"random_forest.joblib\"))\n",
    "# Get best random forest model\n",
    "best_rf= best_rf_pipeline.named_steps[\"regressor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90c7b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature importances into a dataframe\n",
    "feature_results = pd.DataFrame({'feature': feature_columns, \n",
    "                                'importance': best_rf.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c616850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance from random forest'}, ylabel='relative feature importance'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "(feature_results\n",
    "     .sort_values(\"importance\", ascending=False)\n",
    "     .set_index(\"feature\")\n",
    "     .head(10)\n",
    "     .plot.barh(\n",
    "         ax=ax,\n",
    "         color='k',\n",
    "         alpha=0.7,\n",
    "         title=\"Feature importance from random forest\",\n",
    "         xlabel=\"relative feature importance\",\n",
    "         ylabel=\"features\"         \n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9218eda",
   "metadata": {},
   "source": [
    "**There are only a few important determinants of annual salary (from random forest model): being in the computing or tech industry, years of experience and work: (in field experience, overall experience and age). Gender and education level matters but to a relatively smaller extent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82771e68",
   "metadata": {},
   "source": [
    "## 5. Linear Regression Output\n",
    "- Use linear regression from statsmodel to output regression table, and then write it as a TeX or .txt file using stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4d358fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b286c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processed data\n",
    "X_train_processed = salary_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_processed = salary_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5e670be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the OLS model object\n",
    "X_train_processed = sm.add_constant(X_train_processed) # sm does not automatically add constant to predictors\n",
    "feat_names = list(X_train_processed.columns.values)\n",
    " \n",
    "regr = sm.OLS(y_train,\n",
    "              X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "932c44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          annual_salary   R-squared:                       0.402\n",
      "Model:                            OLS   Adj. R-squared:                  0.401\n",
      "Method:                 Least Squares   F-statistic:                     249.8\n",
      "Date:                Tue, 05 Jul 2022   Prob (F-statistic):               0.00\n",
      "Time:                        16:19:39   Log-Likelihood:                -6340.9\n",
      "No. Observations:               16734   AIC:                         1.277e+04\n",
      "Df Residuals:                   16688   BIC:                         1.313e+04\n",
      "Df Model:                          45                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                            10.9001      0.053    205.682      0.000      10.796      11.004\n",
      "age_category                                     -0.0274      0.005     -5.572      0.000      -0.037      -0.018\n",
      "overall_experience                                0.0308      0.004      8.221      0.000       0.023       0.038\n",
      "in_field_experience                               0.0959      0.003     32.249      0.000       0.090       0.102\n",
      "industry_Computing or Tech                        0.6135      0.017     35.739      0.000       0.580       0.647\n",
      "industry_Government and Public Administration     0.2336      0.019     12.424      0.000       0.197       0.270\n",
      "industry_Other                                    0.2315      0.016     14.267      0.000       0.200       0.263\n",
      "industry_Education (Higher Education)             0.0244      0.018      1.373      0.170      -0.010       0.059\n",
      "industry_Law                                      0.2462      0.022     11.086      0.000       0.203       0.290\n",
      "industry_Accounting, Banking & Finance            0.3525      0.019     18.726      0.000       0.316       0.389\n",
      "industry_Nonprofits                               0.1003      0.018      5.648      0.000       0.065       0.135\n",
      "industry_Marketing, Advertising & PR              0.3571      0.021     17.256      0.000       0.317       0.398\n",
      "industry_Health care                              0.3005      0.019     16.134      0.000       0.264       0.337\n",
      "industry_Engineering or Manufacturing             0.4658      0.019     24.569      0.000       0.429       0.503\n",
      "state_Washington                                  0.0861      0.028      3.061      0.002       0.031       0.141\n",
      "state_Other                                      -0.0004      0.021     -0.017      0.986      -0.042       0.041\n",
      "state_Massachusetts                               0.1578      0.026      6.112      0.000       0.107       0.208\n",
      "state_California                                  0.2292      0.023      9.793      0.000       0.183       0.275\n",
      "state_Minnesota                                   0.0495      0.030      1.640      0.101      -0.010       0.109\n",
      "state_Texas                                       0.0887      0.024      3.718      0.000       0.042       0.135\n",
      "state_District of Columbia                        0.2730      0.027     10.251      0.000       0.221       0.325\n",
      "state_New York                                    0.1207      0.025      4.821      0.000       0.072       0.170\n",
      "state_Virginia                                    0.1289      0.026      5.028      0.000       0.079       0.179\n",
      "state_Pennsylvania                                0.0372      0.025      1.509      0.131      -0.011       0.086\n",
      "city_Other                                       -0.1631      0.023     -7.137      0.000      -0.208      -0.118\n",
      "city_Los Angeles                                 -0.1415      0.032     -4.489      0.000      -0.203      -0.080\n",
      "city_Boston                                      -0.0722      0.031     -2.334      0.020      -0.133      -0.012\n",
      "city_Seattle                                     -0.0091      0.033     -0.271      0.786      -0.075       0.057\n",
      "city_San Francisco                                0.0448      0.032      1.415      0.157      -0.017       0.107\n",
      "city_New York                                     0.0136      0.024      0.580      0.562      -0.032       0.060\n",
      "city_Washington                                  -0.1055      0.035     -2.996      0.003      -0.175      -0.036\n",
      "city_Minneapolis                                 -0.0986      0.038     -2.586      0.010      -0.173      -0.024\n",
      "city_Portland                                    -0.0581      0.030     -1.909      0.056      -0.118       0.002\n",
      "city_Chicago                                     -0.0092      0.034     -0.271      0.787      -0.076       0.057\n",
      "gender_Other                                     -0.1629      0.015    -10.669      0.000      -0.193      -0.133\n",
      "gender_Woman                                     -0.0996      0.008    -12.640      0.000      -0.115      -0.084\n",
      "race_White                                       -0.0447      0.017     -2.568      0.010      -0.079      -0.011\n",
      "race_Hispanic, Latino, or Spanish origin         -0.0567      0.026     -2.220      0.026      -0.107      -0.007\n",
      "race_Other                                       -0.0233      0.020     -1.173      0.241      -0.062       0.016\n",
      "race_Asian or Asian American                      0.0697      0.022      3.224      0.001       0.027       0.112\n",
      "education_High School                            -0.3400      0.041     -8.305      0.000      -0.420      -0.260\n",
      "education_Master's degree                         0.0306      0.035      0.865      0.387      -0.039       0.100\n",
      "education_PhD                                     0.2647      0.037      7.114      0.000       0.192       0.338\n",
      "education_College degree                         -0.0880      0.035     -2.497      0.013      -0.157      -0.019\n",
      "education_Some college                           -0.2797      0.037     -7.650      0.000      -0.351      -0.208\n",
      "education_Professional degree (MD, JD, etc.)      0.2953      0.038      7.762      0.000       0.221       0.370\n",
      "==============================================================================\n",
      "Omnibus:                     1658.488   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4854.949\n",
      "Skew:                          -0.536   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.411   Cond. No.                         199.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "res = regr.fit()\n",
    "print(res.summary(xname=feat_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f326c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Stargazer to render regression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "178e845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res must be a sm.ols fitted model with pd.Series (DV) and pd.Dataframe (IV) inputs\n",
    "stargazer = Stargazer([res])\n",
    "\n",
    "# Customize the regression table\n",
    "stargazer.title('Salary survey analysis') # custom title\n",
    "stargazer.show_confidence_intervals(True) # show 95% CI\n",
    "stargazer.rename_covariates({'city_Boston': 'city:Boston'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1132e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Salary survey analysis<br><table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:annual_salary</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">age_category</td><td>-0.027<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.037 , -0.018)</td></tr><tr><td style=\"text-align:left\">city:Boston</td><td>-0.072<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.133 , -0.012)</td></tr><tr><td style=\"text-align:left\">city_Chicago</td><td>-0.009<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.076 , 0.057)</td></tr><tr><td style=\"text-align:left\">city_Los Angeles</td><td>-0.141<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.203 , -0.080)</td></tr><tr><td style=\"text-align:left\">city_Minneapolis</td><td>-0.099<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.173 , -0.024)</td></tr><tr><td style=\"text-align:left\">city_New York</td><td>0.014<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.032 , 0.060)</td></tr><tr><td style=\"text-align:left\">city_Other</td><td>-0.163<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.208 , -0.118)</td></tr><tr><td style=\"text-align:left\">city_Portland</td><td>-0.058<sup>*</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.118 , 0.002)</td></tr><tr><td style=\"text-align:left\">city_San Francisco</td><td>0.045<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.017 , 0.107)</td></tr><tr><td style=\"text-align:left\">city_Seattle</td><td>-0.009<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.075 , 0.057)</td></tr><tr><td style=\"text-align:left\">city_Washington</td><td>-0.106<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.175 , -0.036)</td></tr><tr><td style=\"text-align:left\">const</td><td>10.900<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(10.796 , 11.004)</td></tr><tr><td style=\"text-align:left\">education_College degree</td><td>-0.088<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.157 , -0.019)</td></tr><tr><td style=\"text-align:left\">education_High School</td><td>-0.340<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.420 , -0.260)</td></tr><tr><td style=\"text-align:left\">education_Master's degree</td><td>0.031<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.039 , 0.100)</td></tr><tr><td style=\"text-align:left\">education_PhD</td><td>0.265<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.192 , 0.338)</td></tr><tr><td style=\"text-align:left\">education_Professional degree (MD, JD, etc.)</td><td>0.295<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.221 , 0.370)</td></tr><tr><td style=\"text-align:left\">education_Some college</td><td>-0.280<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.351 , -0.208)</td></tr><tr><td style=\"text-align:left\">gender_Other</td><td>-0.163<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.193 , -0.133)</td></tr><tr><td style=\"text-align:left\">gender_Woman</td><td>-0.100<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.115 , -0.084)</td></tr><tr><td style=\"text-align:left\">in_field_experience</td><td>0.096<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.090 , 0.102)</td></tr><tr><td style=\"text-align:left\">industry_Accounting, Banking & Finance</td><td>0.353<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.316 , 0.389)</td></tr><tr><td style=\"text-align:left\">industry_Computing or Tech</td><td>0.613<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.580 , 0.647)</td></tr><tr><td style=\"text-align:left\">industry_Education (Higher Education)</td><td>0.024<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.010 , 0.059)</td></tr><tr><td style=\"text-align:left\">industry_Engineering or Manufacturing</td><td>0.466<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.429 , 0.503)</td></tr><tr><td style=\"text-align:left\">industry_Government and Public Administration</td><td>0.234<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.197 , 0.270)</td></tr><tr><td style=\"text-align:left\">industry_Health care</td><td>0.301<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.264 , 0.337)</td></tr><tr><td style=\"text-align:left\">industry_Law</td><td>0.246<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.203 , 0.290)</td></tr><tr><td style=\"text-align:left\">industry_Marketing, Advertising & PR</td><td>0.357<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.317 , 0.398)</td></tr><tr><td style=\"text-align:left\">industry_Nonprofits</td><td>0.100<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.065 , 0.135)</td></tr><tr><td style=\"text-align:left\">industry_Other</td><td>0.232<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.200 , 0.263)</td></tr><tr><td style=\"text-align:left\">overall_experience</td><td>0.031<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.023 , 0.038)</td></tr><tr><td style=\"text-align:left\">race_Asian or Asian American</td><td>0.070<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.027 , 0.112)</td></tr><tr><td style=\"text-align:left\">race_Hispanic, Latino, or Spanish origin</td><td>-0.057<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.107 , -0.007)</td></tr><tr><td style=\"text-align:left\">race_Other</td><td>-0.023<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.062 , 0.016)</td></tr><tr><td style=\"text-align:left\">race_White</td><td>-0.045<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.079 , -0.011)</td></tr><tr><td style=\"text-align:left\">state_California</td><td>0.229<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.183 , 0.275)</td></tr><tr><td style=\"text-align:left\">state_District of Columbia</td><td>0.273<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.221 , 0.325)</td></tr><tr><td style=\"text-align:left\">state_Massachusetts</td><td>0.158<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.107 , 0.208)</td></tr><tr><td style=\"text-align:left\">state_Minnesota</td><td>0.050<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.010 , 0.109)</td></tr><tr><td style=\"text-align:left\">state_New York</td><td>0.121<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.072 , 0.170)</td></tr><tr><td style=\"text-align:left\">state_Other</td><td>-0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.042 , 0.041)</td></tr><tr><td style=\"text-align:left\">state_Pennsylvania</td><td>0.037<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(-0.011 , 0.086)</td></tr><tr><td style=\"text-align:left\">state_Texas</td><td>0.089<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.042 , 0.135)</td></tr><tr><td style=\"text-align:left\">state_Virginia</td><td>0.129<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.079 , 0.179)</td></tr><tr><td style=\"text-align:left\">state_Washington</td><td>0.086<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.031 , 0.141)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>16,734</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.402</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.401</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.354 (df=16688)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>249.808<sup>***</sup> (df=45; 16688)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x1374a2070>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stargazer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9f282",
   "metadata": {},
   "source": [
    "**Render html code using stargazer and output .html file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8e418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can render latex code, or html code and write it onto a file\n",
    "html_code=stargazer.render_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d89c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = open(Path(\"outputs\",\"linear_regression_results.html\"), \"w\")\n",
    "_n = html_file.write(html_code)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d00616",
   "metadata": {},
   "source": [
    "**Render LaTeX code using stargazer and output .tex file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cee4161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_code=stargazer.render_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "457f0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_file = open(Path(\"outputs\",\"linear_regression_results.tex\"), \"w\")\n",
    "_n = tex_file.write(tex_code)\n",
    "tex_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
